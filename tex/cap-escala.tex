
\chapter{Computação em Grande Escala}
\label{cap:escala}

Na visão proposta pelo Instituto de Engenharia de Software da Universidade Carnegie Mellon, sistemas de ultra grande escala serão ultra grandes em relação a todas as dimensões possíveis: linhas de código, pessoas, dados, dispositivos, etc.~\cite{CarnegieMellon2006ULS}. O número estimado de linhas de código desses sistemas é de bilhões. Para efeito de comparação, o núcleo do sistema operacional GNU/Linux possui cerca de 15 milhões de linhas de código em sua versão 3.2, a mais recente no momento da escrita deste texto~\cite{Leemhuis2012Statistics}. Com isso, o único sistema da atualidade que se assemelha aos sistemas de escala ultra grande previstos é a Internet. 

\gerosa{Será que faz sentido considerar o core do Linux? Para mim faria mais sentido pegar o total de linhas de código de uma distribuição Linux inteira, incluindo o núcleo e todos os software, o que deve passar de 1 bilhão.} \Leo{não sei se pegar uma distribuição inteira seria boa ideia, pois possui centenas de softwares que são opcionais e que geralmente não são instalados. procurando rapidamente no google, achei um chute de umas 100 milhões LOC para o Ubuntu. de qlqr forma, LOC não é mesmo qo define ULS, conforme explicado mais a baixo... por isso eu manteria a comparação com o kernel ou removeria essa comparação.}

A característica mais importante de um sistema de grande escala não é seu tamanho, mas o fato de ser caracterizado como um ``ecossistema sociotécnico''~\cite{CarnegieMellon2006ULS}, em que pessoas são parte integrante do sistema, interagindo com diferentes objetivos, de modo decentralizado e independente, porém seguindo restrições impostas. A analogia proposta é de que o desenvolvimento dos atuais sistemas de grande escala se equipara a construção de prédios, enquanto que o desenvolvimento de sistemas de escala ultra grande equivaleriam a construção de cidades, o que é naturalmente um processo contínuo e decentralizado.

Sistemas de escala ultra grande ainda não são uma realidade, mas alguns dos desafios para viabilizar suas características já têm sido enfrentados pela indústria de software no desenvolvimento dos atuais sistemas de grande escala. Em nosso trabalho, consideraremos as contribuições que a academia e a indústria têm fornecido no sentido de viabilizar as seguintes características de sistemas de ultra grande escala:

\begin{description}

\item [Descentralização] Sistemas de grande escala não possuem um único dono~\cite{Steen2011VeryLarge}, sendo que seus componentes pertencem a diferentes organizações que interagem de forma coordenada. Um dos principais caminhos para viabilizar essa característica é a Arquitetura Orientada a Serviços, incluindo as coreografias de serviços web, já descritas no capítulo anterior.

\item [Evolução e implantação contínua] Um sistema de ultra grande escala não é implantado de uma única vez, mas evolui ao longo de sua vida. Humble e Farley~\cite{Humble2011Continuous} apresentam recomendações sobre como tornar a implantação de sistemas mais disciplinada e confiável, constituindo uma visão moderna da indústria de software sobre o tema. Ao longo de nosso trabalho, consideraremos essas recomendações. 

\item [Falhas corriqueiras] Por mais que a probabilidade de falha em cada componente seja pequena, a grande quantidade de componentes e de interações entre eles eleva significativamente a probabilidade de que alguma falha ocorra no sistema em um dado intervalo de tempo. Mais do que ser projetado para não falhar, um componente operando em um ambiente de escala ultra grande ou grande escala deve ser projetado para tratar adequadamente situações de exceção e indisponibilidade, tanto do próprio componente, quanto de outros componentes dos quais depende. 

\end{description}

Recentemente temos ainda a consolidação da computação em nuvem, que traz um conjunto de tecnologias e práticas que se relacionam com as três características de sistemas de escala ultra grande anteriormente mencionadas. Sistemas distribuídos estão migrando para ambientes de nuvem, onde são compostos e mantidos decentralizadamente por várias organizações~\cite{Steen2011VeryLarge}. A virtualização, um dos aspectos centrais da computação em nuvem, é de grande auxílio no provisionamento de novos ambientes~\cite{Humble2011Continuous}, o que é importante para o processo de implantação de sistemas. A virtualização também facilita a criação de ambientes replicados, arquitetura importante para tratar falhas individuais de componentes.

No restante desta seção apresentaremos estudos que identificam desafios, práticas e princípios já explorados no desenvolvimento dos atuais sistemas de grande escala. Também destacaremos a computação em nuvem, muito importante para o gerenciamento e operação desses sistemas de grande escala.

\section{Desafios, práticas e princípios em sistemas de grande escala}

Eric Brewer é um dos primeiros autores a apresentarem recomendações práticas para o desenvolvimento de sistemas de grande escala~\cite{Brewer2001GiantScale}. A primeira prática apresentada é utilização de aglomerados, associada ao balanceamento de carga entre os nós do aglomerado. O balanceamento de carga é um dos pontos mais importantes e recomendados atualmente para que sistemas se tornem escaláveis~\cite{Amazon2012Practices}. Propriedades fornecidas pelo uso de aglomerados, como falhas independentes e escalabilidade incremental, levaram ao posterior desenvolvimento do conceito de computação em nuvem, descrito em mais detalhes na próxima subseção. 

Hamilton~\cite{Hamilton2007InternetScale} lista uma série de boas práticas acumuladas por anos de experiência no desenvolvimento de serviços de grande escala. Segundo Hamilton, o objetivo das práticas recomendadas é fazer com que o sistema seja operado por uma pequena equipe de administradores, de modo que em caso de falhas seja necessária pouca intervenção humana para o diagnóstico e recuperação do sistema. Os três principais princípios colocados por Hamilton consistem em 1) simplicidade nas decisões arquiteturais, 2) automação das operações e 3) esperar que falhas ocorram e tratá-las adequadamente.

Simplicidade no projeto ajuda na detecção e correção de erros. A simplicidade também é importante na hora de tomar decisões operacionais. Tais decisões devem ser aplicadas de forma simples, mesmo que para isso o projeto sacrifique algum desempenho.

A automação de todos os processos evita perda de tempo e evita o risco de falhas humanas introduzidas pelos operadores, que se tornariam ainda mais prováveis em sistemas de grande escala. Para Humble e Farley~\cite{Humble2011Continuous}, a capacidade de se liberar constantemente novas versões do software está condicionada a um processo automatizado de testes, implantação e ``roll-back'' no ambiente de produção. Além disso, Humble e Farley aconselham que alterações em nós no ambiente de produção sejam feitas através de scripts, evitando a realização de procedimentos manuais nesses nós.

Brewer~\cite{Brewer2001GiantScale} recomenda que atualizações sejam automatizadas e que sejam encaradas como falhas temporárias, uma vez que implicam em uma redução de desempenho ou disponibilidade. A orientação é priorizar um dos aspetos. Também se espera que a atualização seja dinâmica, ou seja, que não seja preciso desligar o sistema para atualizá-lo. Para atingir esse objetivo utilizar-se o ambiente de homologação para a implantação da nova versão, enquanto a versão antiga recebe suas últimas requisições no ambiente de produção; após a implantação, o ambiente de homologação se torna ambiente de produção e vice-versa. Técnicas de atualização dinâmica utilizadas pela indústria, como o ``Blue-Green deployment'' e o ``Canary releasing''~\cite{Humble2011Continuous}, estão em sintonia com essas recomendações feitas por Brewer.

Outra automação importante é o ``roll-back'' do sistema: se o ambiente de produção se encontrar em algum estado inválido, é preciso uma reversão rápida e segura do sistema e do ambiente para o última estado estável~\cite{Hamilton2007InternetScale, Brewer2001GiantScale}. Nygard~\cite{Nygard2009Release} advoga que em caso de falha no sistema a prioridade deve ser a reversão imediata do sistema para a sua última versão estável, deixando para depois as investigações sobre as razões do problema\footnote{A ordem inversa é tentadora, mas a reversão do sistema pode eliminar pistas da investigação.}. A recomendação de Brewer de que uma nova versão de um serviço mantenha sua interface compatível com a versão anterior é também de grande auxílio para uma reversão automatizada, pois não é preciso se preocupar com o código do cliente.

Sistemas de grande escala são compostos por vários pequenos componentes que interagem entre si. A grande quantidade de componentes e de requisições faz com que surjam sequências de interações não previstas e não testadas na fase de desenvolvimento. Nesse cenário é certo que em algum momento algum dos componentes irá falhar. Além das falhas dos componentes, é importante também considerar que interações entre componentes podem sofrer grande latência, situação às vezes indistinguível de uma falha. Vários autores defendem que um sistema distribuído seja projetado para que a falha individual de seus componentes não provoque uma falha total em todo o sistema~\cite{Hamilton2007InternetScale, Helland2009Quicksand, Nygard2009Release, CarnegieMellon2006ULS}. 

Essas falhas devem ser sempre esperadas, mesmo com o emprego de outras precauções como o balanceamento de carga entre componentes e a replicação de dados~\cite{Brewer2001GiantScale}. Para tratar as falhas, tanto Brewer~\cite{Brewer2001GiantScale} e Hamilton~\cite{Hamilton2007InternetScale} advogam o uso do conceito de \emph{}degradação suave\emph{}, em que as falhas nos componentes implicam na redução de funcionalidades do sistema, mas nunca em um sistema indisponível.

Nygard~\cite{Nygard2009Release} apresenta vários padrões de estabilidade que são de importante aplicação em sistemas de grande escala. Em sua essência, esses padrões dizem respeito a detectar falhas e evitar sua propagação, provendo um tratamento adequado a essas falhas. Dentre as práticas recomendas pelo autor destacam-se 1) o uso de \emph{timeouts} no cliente, que evita que um cliente fique eternamente esperando uma resposta; 2) a interrupção de tentativas do cliente quando há sintomas de indisponibilidade do provedor; 3) criação de recursos exclusivos para diferentes clientes, evitando que uma falha em um recurso compartilhado afete todos os clientes; e 4) a ``falha rápida'', que faz com que um provedor forneça uma resposta de erro tão logo quanto seja possível saber que a operação não terá sucesso.

Uma das práticas muito utilizadas em sistemas de grande escala é a replicação dos dados, que é utilizada não somente para cópias de segurança, mas como uma medida para aumentar a disponibilidade do sistema, uma vez que se uma das réplicas falhar, a outra pode continuar a disponibilizar os dados~\cite{Brewer2001GiantScale}. Além da replicação, Brewer também comenta sobre o uso do particionamento de dados, situação em que nós diferentes armazenam conjuntos disjuntos de dados. Um bom projeto de particionamento leva a um aumento de desempenho, embora ponha em risco a disponibilidade do sistema. Na prática, sistemas utilizam um misto de particionamento e replicação.

Helland~\cite{Helland2009Quicksand} explica como sistemas de grande escala não dão suporte à replicação síncrona de seus dados. Isso significa que um componente responde ao usuário antes de ter certeza de que a cópia adicional foi efetivada. Uma falha no componente primário em um instante entre o processamento de uma requisição e a replicação de seus efeitos pode ocasionar perda de trabalho. Segundo Helland, em um ambiente de grande escala esse compromisso é aceitável, pois outros fatores, como \emph{timeouts}, também levam a falhas similares. Dessa forma, trocam-se propriedades de consistência por disponibilidade e redução de latência.

O compromisso entre disponibilidade e consistência é tema do Teorema CAP~\cite{Brewer2012Cap}, que prevê que um sistema não mantém os níveis de consistência e de disponibilidade na presença de particionamentos de rede. Considerando que particionamentos de rede são intrínsecos ao ambiente da Internet, o aumento no tamanho dos sistemas inviabilizou uma consistência total com tempo de resposta satisfatório.  Na área de banco de dados em particular, essa mudança representou uma quebra de paradigma, pois até então bancos de dados eram projetados para fornecer as propriedades ACID, que garantem consistência total. Atualmente se tornam cada vez mais populares os chamados bancos de dados não-relacionais (NoSQL), que diminuem a consistência dos dados fornecidos quando a replicação dos dados é necessária~\cite{REF_NEEDED}. 

Um exemplo clássico de redução de consistência para se conseguir aumento de disponibilidade é o carrinho de compras da Amazon, no qual um item excluído nem sempre é efetivamente excluído. Algumas inconsistências como essa podem levar a um ``erro'' do ponto de vista do negócio. Isso leva Hellend ao conceito de ``desculpas''. Mesmo sem saber se o sistema poderá honrar seus compromissos, ele se engaja em uma transação e caso a transação não possa ser completada mais tarde, um pedido de desculpa deve ser oferecido ao cliente, eventualmente com alguma compensação. Do ponto de vista da modelagem de um processo de negócio, isso implica na necessidade da modelagem de atividades de compensação~\cite{Garcia1991Saga} em detrimento da utilização de protocolos síncronos que tentam garantir o sucesso da transação, como o protocolo de \textit{Two Phase Commit} (2PC) \cite{Bernstein20092PC}.

Outra consequência da replicação assíncrona de dados é que usuários acessando cópias diferentes dos dados enxergam o sistema de formas diferentes. Hellend ressalta que é importante que o sistemas forneça consistência em tempo indeterminado, ou seja, essa diferente visão do sistema tem que ser conciliada em tempo finito. Hellend também afirma que a forma como o sistema trabalha com a informação durante o período inconsistente deve estar a cargo da camada de aplicação. Um cuidado que a aplicação deve tomar é para que o resultado da sincronização de dados de múltiplas cópias não dependa da ordem de chegada dos pedidos de sincronização, sendo assim desejável que as operações sejam idempotentes e comutativas. 

A idempotência deve ser usada sempre que possível também por outro motivo. Quando um sistema faz uma requisição a outro serviço, não é possível distinguir um \emph{timeout} de uma resposta eventualmente mais lenta. Dessa forma, só é seguro, do ponto de vista funcional, o sistema cliente enviar uma nova requisição devido a \emph{timeout} caso a operação considerada seja idempotente. Em sistemas REST, por exemplo, todas as operações que não sejam POST devem ser idempotentes~\cite{Allamaraju2010REST}.

A Tabela~\ref{tab:escala} apresenta uma lista que resume as principais práticas e princípios adotados para o suporte de sistemas de grande escala. Tais práticas e princípios foram retiradas dos estudos já apresentados nesta subseção.

\begin{table}[!t]
\begin{center}
    \begin{tabular}{l}
	 \hline
Manter a simplicidade nas escolhas \\
Automatizar o que puder \\
Ausência de ponto único de falha \\
Replicação de componentes \\
Uso de aglomerados \\
Balanceamento de carga \\
Particionamento de dados \\
Replicação de dados \\
Ausência de estado global  \\% ainda não foi abordado no texto
Esperar falhas e latências  \\
Lidar com falhas usando degradação suave \\
Permitir períodos de inconsistências, oferecendo desculpas quando necessário \\
Inconsistências temporárias são tratadas na camada da aplicação \\
Não utilizar transações distribuídas síncronas \\
Melhor usar componentes sem estado  \\% ainda não foi abordado no texto
Melhor usar operações idempotentes e comutativas \\
Atualização dinâmica \\
Compatibilidade com versão anterior \\
Suporte a \emph{roll-back} de versão \\
	 \hline
    \end{tabular}
  \caption{Práticas adotadas em sistemas de grande escala}
  \label{tab:escala}
\end{center}
\end{table}

O ``uso de aglomerados'' foi sugerido por Brewer~\cite{Brewer2001GiantScale} em um contexto em que esses aglomerados residiam em um mesmo centro de dados, não sendo geograficamente distribuídos. No entanto, as práticas de utilização de aglomeradas evoluíram consideravelmente com o uso da chamada computação em nuvem, apresentada a seguir.

\section{Computação em Nuvem}

Várias das práticas para computação em grande escala vistas na subseção anterior são facilitadas pela utilização da computação em nuvem. O rápido provisionamento e reversão de ambientes de produção é possibilitado pelo emprego dos serviços de virtualização oferecidos pela nuvem.

O Instituto Nacional de Padrões e Tecnologias dos Estados Unidos (NIST) define computação em nuvem como um ``modelo para possibilitar acesso ubíquo, conveniente e sob demanda pela rede a um conjunto compartilhado de recursos computacionais (por exemplo: redes, servidores, discos, aplicações e serviços) que possam ser rapidamente provisionados e liberados com o mínimo de esforço gerencial ou interação com o provedor do serviço''~\cite{Nist2011Cloud}. 

Zhang et al.~\cite{Zhang2010Cloud} destacam as seguintes características da computação em nuvem: i) separação de responsabilidades entre o dono da infraestrutura de nuvem e o dono do serviço implantado na nuvem; ii) compartilhamento de recursos (serviços de diferentes organizações hospedados na mesma máquina, por exemplo); iii) geodistribuição e acesso aos recursos pela Internet; iv) orientação a serviço como modelo de negócio; v) provisionamento dinâmico de recursos; vi) cobrança baseada no uso de recursos, de forma análoga à conta de eletricidade.

Os serviços de computação em nuvem poder ser oferecidos a clientes internos ou externos à organização administradora da plataforma de nuvem. Quando os clientes são externos dizemos que a nuvem é pública, como no caso da nuvem da Amazon; quando os clientes são internos, dizemos que a nuvem é privada, situação na qual a organização pode utilizar ambientes baseados em um middleware como o OpenStack~\cite{Zhang2010Cloud}.

Ao modelo de computação em nuvem é atribuído as seguintes camadas, denominadas modelos de negócio~\cite{Zhang2010Cloud} ou modelos de serviço~\cite{Nist2011Cloud}: Infraestrutura como um Serviço (IaaS), Plataforma como um Serviço (PaaS) e Software como um Serviço (SaaS). 

O modelo de Infraestrutura como Serviço (IaaS) fornece acesso aos recursos virtualizados, como máquinas virtuais, de forma programática. Um dos principais fornecedores atuais de IaaS é a Amazon, com os serviços Amazon Web Services (AWS). Dentre os vários serviços fornecidos pela plataforma, destaca-se o EC2, que possibilita a criação e gerenciamento de máquinas virtuais na nuvem da Amazon.

Na utilização de IaaS, uma das considerações chaves é ``tratar hospedeiros como efêmeros e dinâmicos'' (Amazon2012Practices). É preciso considerar que hospedeiros podem ficar indisponíveis e que nenhuma suposição pode ser feita sobre seus endereços IPs, o que requer um modelo de configuração flexível e que a inicialização do hospedeiro leve em conta essa natureza dinâmica da nuvem. Para que as aplicações sejam escaláveis e tolerantes a falhas, a Amazon recomenda mais do que a criação de máquinas virtuais com o serviço EC2: deve-se utilizar grupos de máquinas replicadas que compartilhem um balanceador de carga~\cite{Amazon2012Practices}. Conforme a demanda da aplicação cresce ou diminui, máquinas podem ser dinamicamente acrescentadas ou removidas desses grupos de replicação, o que proporciona escalabilidade horizontal à aplicação. Naturalmente, essa replicação depende de um prévio preparo da aplicação para esse cenário, pois se deve levar em conta a distribuição, replicação e particionamento dos dados. 

Um exemplo típico de PaaS é o Google App Engine, que oferece implantação transparente a projetos em Python, Java ou Go. Nesse caso, os desenvolvedores da aplicação não precisam se preocupar diretamente com a gerência dos recursos virtualizados ou com a configuração dos ambientes nos quais a aplicação será implantada, concentrando-se no desenvolvimento do código da aplicação. O Google App Engine também oferece escalabilidade automática de modo mais simples que os serviços de IaaS, uma vez que a configuração prévia e as alterações na infraestrutura ocorrem de modo totalmente transparente ao desenvolvedor da aplicação. Uma desvantagem presente nos serviços PaaS são as restrições de linguagens, bibliotecas e ambientes impostas aos desenvolvedores da aplicação.

Como exemplo de SaaS temos o Google Docs ou qualquer outro aplicativo online que seja diretamente utilizado pelo usuário final. Uma das aplicações desse tipo é o armazenamento de dados na nuvem, como fornecido pelo Dropbox\footnote{\url{http://dropbox.com/}}. Uma confusão comum é definir o conceito de nuvem como se fosse estritamente ligado a esse tipo de serviço de armazenamento de dados.

Com as vantagens aqui apresentadas, é cada vez mais comum o uso dos recursos de nuvem por empresas que desenvolvem software, pois assim seus esforços se concentram no desenvolvimento do produto, aliviando as preocupações com infraestrutura. A computação em nuvem também possibilita que organizações evitem grandes investimentos antecipados em infraestrutura, pois os recursos virtualizados são dinamicamente acrescentados conforme a carga da aplicação requeira. Pode-se então considerar o uso da nuvem uma realidade do mercado de software atual. Dessa forma, é natural esperar que a implantação de composições de serviços também se dê no ambiente de computação em nuvem, que é a abordagem deste trabalho. 
