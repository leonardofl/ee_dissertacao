%% ------------------------------------------------------------------------- %%
\chapter{Conclusões}
\label{cap:conclusoes}

\leo{conclusões em andamento...}

Nesta dissertação, nós introduzimos o CHOReOS \ee,
um novo sistema de middleware que facilita a implantação de composições
de serviços de grande escala em um ambiente de computação em nuvem.

Embora a automação do processo de implantação de composições de serviços
possa ser implementado de maneiras \emph{ad-hoc},
esse tipo de solução normalmente requer de implantador
uma grande gama de conhecimentos técnicos.
Por meio de experimentos, procuramos evidenciar como
uma abordagem baseada em middleware, como o EE,
reduz o tempo de trabalho necessário para a automação
do processo de implantação, considerando tanto o tempo
de desenvolvimento de soluções de implantação,
quanto o tempo de implantação de cada composição.
Procuramos mostrar também qualitativamente como
o uso de uma solução baseada em middleware
melhora a qualidade final do processo de implantação,
uma vez que diversas complicações são tratadas
na camada do middleware, tais como concorrência
e tratamento de falhas de terceiros.

Ao revisar a literatura identificamos várias necessidades e soluções
para sistemas de grande escala, dentre as quais procuramos aplicar
aquelas adequadas ao contexto de implantação de sistemas.
\todo{falar mais da seção de discussão}

Ao conduzir experimentos de grande escala,
tal prática se mostrou recompensadora.
Resultados experimentais evidenciam a aplicabilidade da arquitetura proposta
e que desempenho e escalabilidade satisfatórios podem ser obtidos.
\todo{falar mais da seção de avaliação de escalabilidade}

Acreditamos no potencial do \ee em apoiar outras pesquisas
sobre composições de serviços, e acreditamos que as lições aprendidas
ao se implantar o \ee e os princípios arquiteturais aplicados
podem auxiliar no desenvolvimento de outras soluções baseadas
em middleware no contexto de computação de grande escala.

Como lições aprendidas durante o desenvolvimento do EE e desta dissertação podemos destacar:

\begin{itemize}
\item gargalo do chef server. filas (rabbit), tidas como escaláveis, ajudam com vazão, mas não com tempo de resposta. mas o q atrapalhou mesmo foi a grande quantidade de req para esse componente altamente central no sistema.
\item desenvolvimento iterativo foi bom, mas um certo up-front design modular mais atrapalhou, e no fim o design foi simplificado sucessivamente.
\end{itemize}




\section{Sugestões para trabalhos futuros}

Listamos agora alguns possíveis trabalhos futuros envolvendo o \ee.

\begin{description}

\item[Análise da influência dos tratamentos de falhas na escalabilidade.] 
Ao analisar a escalabilidade fornecida pelo \ee ao processo de implantação,
não determinamos o quanto dessa escalabilidade se deve graças aos mecanismos 
presentes no EE que tratam falhas de terceiros.
Um experimento a se fazer nesse sentido seria replicar o experimento 
de escalabilidade (Figura~\ref{fig:ee_scalability})
primeiramente desativando a reserva de nós ociosos e posteriormente
desativando também os \emph{invokers}.
Dessa forma poderíamos comparar três curvas em um mesmo plano
a fim de determinar o quanto que os mecanismos de tratamento de falhas
do EE melhoram a escalabilidade do processo de implantação de composições de serviços.

\item[Análise multivariável de fatores que influenciam a escalabilidade.] 
Outro experimento para melhor entender o desempenho e escalabilidade do EE
seria aplicar uma análise multivariável para determinar o quanto
que o tempo de implantação é influenciado por fatores como a quantidade de composições
sendo implantada, a quantidade de serviços em cada composição e a quantidade
de nós disponíveis.
Nesse sentido, começamos a realizar esse experimento utilizando a análise fatorial $2^k$
com replicação~\cite{Jain20002kr}, mas dificuldades com a distribuição dos dados e o alto custo
para se obter novas amostras dificultaram a conclusão desse experimento.

\item[Experimentos com desenvolvedores.] 
Na Seção~\ref{sec:avaliacao_eng_sw} realizamos uma avaliação qualitativa para
ajudar a expandir nosso entendimento sobre o valor que o EE agrega ao processo de implantação.
Dada as limitações de nosso experimento, seria interessante expandi-lo
com a participação de diversos desenvolvedores de software
e administradores de sistemas assumindo o papel de implantadores de uma composição de serviços.
Nesse caso, a ideia seria utilizar uma abordagem mais rigorosa,
dentro das possibilidades de experimentos de engenharia de software.
Comparações com outros arcabouços de implantação também poderiam ser realizadas.

\item[Algoritmos adaptativos para tratamento de falhas.] 
Acreditamos que os algoritmos do EE que tratam falhas de terceiros podem ser melhorados.
Tanto a reserva de nós ociosos quanto o \emph{invoker} são adequados 
para utilizarem algoritmos adaptativos que aprendem com o histórico de
execuções. Assim, a reserva de nós ociosos poderia alterar seu tamanho dinamicamente,
evitando desperdícios de VMs extras. Da mesma forma, o \emph{invoker}
poderia utilizar valores de \emph{timeout} mais adequados, evitando longas
esperas desnecessárias ou desistindo de tarefas que logo estariam prontas.
Um desafio interessante para a adaptação dinâmica do \emph{invoker} é
considerar a alteração dinâmica de suas três propriedades:
\emph{timeout}, quantidade de tentativas e tempo de pausa entre as tentativas.

\item[Federação de instâncias do EE.] Uma instância do EE realiza a implantação
de serviços pertencentes a uma dada organização. Se algum dos serviços implantados
depende de um serviço pertencente a outra organização, o implantador
pode modelar esse serviço de terceiros como um \emph{serviço legado}
na modelagem da composição. O problema é que mudanças nos serviços de
terceiros, como mudança de URI, podem causar impactos na composição implantada.
Além disso, se serviços interdependentes de diferentes organizações são implantados em paralelo,
torna-se difícil utilizar o recurso de \emph{serviço legado},
uma vez que o implantador de uma organização ainda não dispões das URIs 
dos serviços sendo implantados pela outra organização.
Para tornar a implantação de composições inter-organizacionais mais dinâmica,
um caminho promissor é a federação de instâncias do EE.
Assim, uma instância pertencente a uma organização $A$ pode avisar a
uma outra instância pertencente a uma organização $B$ sobre mudanças 
nas coreografias de $A$ que possam impactar as coreografias pertencentes a $B$.

\item[Utilização de um balanceador de carga.] Na atual implementação do EE,
quando um serviço é replicado em várias instâncias, seus clientes
recebem as URIs de todas as instâncias disponíveis do serviço.
Assim, cabe a cada cliente distribuir a carga pelas diferentes réplicas disponíveis.
No entanto, melhor seria que o EE implantasse um balanceador de carga 
que distribuísse as requisições entre as diferentes instâncias do serviço.
Assim, os clientes receberiam apenas uma URI, que seria a URI
do balanceador de carga.

\item[Utilização de um barramento de serviços.] Caso um serviço dependa
de outro serviço com um protocolo de comunicação diferente, o EE assume que é de
responsabilidade do serviço cliente conhecer o protocolo do serviço provedor.
Contudo, para facilitar a implementação dos serviços, a conversão entre
diferentes protocolos de comunicação poderia ser tratada por um barramento de serviços.
Assim, uma possibilidade seria de que o EE implantasse automaticamente instâncias
de um barramento de serviços para interligar serviços de protocolos diferentes.
No entanto, para essa tarefa é necessário a utilização de um barramento de serviços
que considere a natureza dinâmica de ambientes de computação em nuvem,
onde serviços são replicados e passam a possuir múltiplas URIs.

\item[Atualização dinâmica de composições de serviços.] Na atual implementação do EE,
a atualização de coreografias pode ocasionar falhas em transações correntes,
o que ocorre mesmo com serviços sem estado.
Vários trabalhos \cite{Kramer1990Philosophers, Vandewoude2007Tranquility, Xiaoxing2011VersionConsistent} 
estudam o processo de atualização dinâmica, pelo qual as transações correntes 
são preservadas durante a atualização de um serviço. 
Acreditamos que seria muito interessante possibilitar ao administrador do EE
a definição de políticas e algoritmos de atualização para 
tratar da adequada finalização das transações correntes.
Dessa forma, o EE poderia se tornar uma plataforma de apoio
à comparação empírica entre diferentes estratégias presentes na literatura.

\end{description}

Outras pendências menores estão registradas na página de \emph{issues} 
do \ee\footnote{\url{https://github.com/choreos/enactment_engine/issues?state=open}}.
Colaborações técnicas e de pesquisa sobre as possibilidades levantadas
são bem vindas.


\section{Palavras finais}


algo sobre continous delivery, espírito ágil (se expandindo, design think, lean): iteratividade... 
tudo q ajude a acelerar o ciclos de iterações em todos os níveis
(codificação, implantação, negócio) é importante.

importância disso para sistema de grande escala, onde up front design é mt mais difícil.
importância da grande escala, especialmente para composição de serviços...
posso citar integração de fluxos de negócios empresariais,
mas tb integração governamental para uma maior inteligência a serviço da sociedade
(uma composição que envolvesse todos os municípios já seria bem grande).

algo sobre computação em nuvem como importante apoiador dessa transformação,
permitindo q o princípio de iteratividade se aplique mais facilmente
às atividades de implantação.

No futuro... maior automação e integração não só dos serviços,
mas do próprio processo de desenvolvimento de SW.



