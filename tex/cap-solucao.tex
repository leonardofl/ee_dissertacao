\chapter{Solução proposta: o \ee}
\label{cap:solucao}

O CHOReOS \ee (EE) é um middleware implementado no contexto deste trabalho.
Uma vez instanciado, ele fornece serviços que automatizam
a implantação de composições de serviços\footnote{Como explicado na Seção~\ref{sec:composicoes}, usaremos os termos 
``composição de serviço'' e ``coreografia'' indistintamente.} 
em ambientes de computação em nuvem,
funcionando no modelo de computação em nuvem denominado Plataforma como um Serviço (PaaS).
O EE possui funcionalidades e características que foram projetadas para auxiliar o
implantador na implantação de composições de grande escala.

Para utilizar o EE, o implantador, usuário do EE, deve descrever a composição a ser implantada
na Linguagem de Descrição Arquitetural do EE, uma especificação de alto nível que
diz \emph{o que} deve ser implantado, e não o \emph{como}. 
Finalmente, o usuário deve fornecer essa descrição ao EE através de sua API remota.

As funcionalidades fornecidas pelo \ee ao usuário são as seguintes:

\begin{itemize}
\item API para automatizar a implantação de composições de serviços em ambientes de computação em nuvem.
\item Criação automatiza de infraestrutura virtualizada (nós na nuvem).
\item Implantação escalável de coreografias de grande escala.
\item Suporte a implantação multi-nuvem.
\item Utilização de serviços de terceiros na composição a ser implantada.
\item Implantação automatizada de infraestrutura de monitoramento dos recursos utilizados.
\item Deleção automática de recursos da nuvem não utilizados.
\item API para escalamento vertical e horizontal.
\end{itemize}

Para a implementação do arcabouço Enactment Engine contribuíram Daniel Cuckier, Carlos Eduardo do Santos, Felipe Pontes, Alfonso Diaz, Nelson Lago, Paulo Moura, Thiago Furtado e demais colegas dos projetos Baile e CHOReOS. O \ee é software livre 
sob a Licença Pública Mozilla 2\footnote{\url{http://www.mozilla.org/MPL/2.0/}} 
e está disponível em \url{http://ccsl.ime.usp.br/enactmentengine}. 

Neste capítulo, nós apresentamos a arquitetura e aspectos de implementação do \ee.   
Destacamos ao final do capítulo
como as decisões arquiteturais e de implementação auxiliam o implantador
a superar os desafios presentes na implantação de composições de grande escala.
Alguns aspectos aqui discutidos serão tratados em alto nível,
priorizando o que é importante para o entendimento das contribuições
acadêmicas deste trabalho.
Detalhes de mais baixo nível sobre nosso middleware, principalmente do ponto de vista do
usuário, podem ser encontrados no \userguide (Apêndice~\ref{ape:user_guide}).

\section{Execução do \ee}

O \ee é um sistema de middleware de código aberto que primeiramente deve ser instalado e configurado por um \emph{administrador}.
Uma vez em execução, a instância do EE fornece serviços que podem ser consumidos por algum sistema cliente, desenvolvido
e operado pela figura do \emph{implantador}. O administrador e o implantador podem pertencer à mesma organização,
mas é possível que o administrador forneça o EE como um serviço (SaaS) a terceiros, cobrando por sua utilização.
Para esses terceiros a vantagem seria evitar o trabalho de instalação e configuração do EE.
O ambiente de execução do EE é exibido na Figura~\ref{fig:arquitetura} e os componentes envolvidos são descritos a seguir.

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\linewidth]{arquitetura.pdf}
\caption{Ambiente de execução do \choreos \ee.}
\label{fig:arquitetura}
\end{figure}

\begin{itemize}

\item O \emph{provedor de infraestrutura} é um serviço capaz de criar e destruir máquinas virtuais 
(também chamadas de \emph{nós}), normalmente em um ambiente de computação em nuvem. 
Atualmente o \ee suporta o Amazon EC2 e o OpenStack.

\item O \emph{agente de configuração} é executado nos nós alvos
e dispara os scripts que implementam as fases de preparação
e inicialização da implantação dos serviços\footnote{Sobre a nomenclatura das fases de implantação, ver a Seção~\ref{sec:implantacao}.}.
O \ee utiliza o Chef Solo\footnote{\url{http://docs.opscode.com/chef_solo.html}}
como seu agente de configuração.

\item O \emph{cliente do \ee} é um programa ou script desenvolvido
pelo implantador, no qual a especificação da composição de serviços é definida.
Esse script deve enviar a especificação da composição para o \ee
através das operações REST fornecidas pelo \ee.
Uma opção para implementar essas chamadas é utilizar
a biblioteca Java por nós fornecida, que abstrai os detalhes
das chamadas REST.

\item O \emph{\ee} implanta os serviços de uma composição
com base na especificação enviada pelo cliente.
O processo implementado pelo \ee para efetuar a implementação
é descrito na Figura~\ref{fig:processo}, e explicado logo em seguida. 

\end{itemize} 

A Figura~\ref{fig:processo} exibe o processo de implantação de composições
de serviços implementado pelo \ee:

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{processo.pdf}
\caption{Processo de implantação implementado pelo \ee.}
\label{fig:processo}
\end{figure}

\begin{enumerate}

\item \emph{Requisição do cliente:} o EE recebe a especificação da composição a ser implantada.
O formato dessa especificação é descrito na Seção~\ref{sec:spec}.

\item \emph{Seleção/criação de nós}: para cada serviço especificado, o EE seleciona um ou mais nós 
onde o serviço será implantado (um serviço pode ter várias réplicas implantadas). 
Se preciso, o EE requisitará ao provedor de infraestrutura a criação de novos nós.
Esse processo de seleção/criação de nós pode levar em conta os requisitos não-funcionais
dos serviços a serem implantados.
A política de seleção de nós é definida pelo administrador do EE, sendo que novas políticas podem ser criadas.

\item \emph{Geração de scripts}: para cada serviço da composição, 
o EE gera dinamicamente os scripts de preparação do ambiente e inicialização do serviço. 
O EE acessa então o nó alvo selecionado para o serviço,
e configura o agente de configuração desse nó para executar o script gerado.

\item \emph{Atualização dos nós}: para cada nó alvo que receberá serviços da composição,
o EE dispara a execução do agente de configuração, que por sua vez executa os scripts 
de preparação e inicialização dos serviços atribuídos ao nó.
Dessa forma, os serviços entram em estado de execução na infraestrutura alvo.

\item \emph{Ligação entre serviços}: após os serviços terem sido iniciados, 
para cada relação de dependência na coreografia (ex: serviço \textsf{TravelAgency}
depende do serviço \textsf{Airline}), o EE fornece o endereço da dependência 
(ex: \url{http://airline.com/ws}) ao serviço dependente.
Mais informações sobre o processo de ligação são fornecidas na Seção~\ref{sec:ligacao}.

\item \emph{Resposta para o cliente}: o EE responde ao seu cliente,
informando em que nó cada serviço foi implantado
e as URIs de acesso a cada serviço da composição.
O formato da resposta é descrito na Seção~\ref{sec:spec}.

\end{enumerate}

Há também alguns outros passos opcionais que não descrevemos por estarem fora
do escopo deste trabalho. Um exemplo é a implantação da infra-estrutura de monitoramento
dos nós alvos. O agente de monitoramento 
(Ganglia\footnote{\url{http://ganglia.sourceforge.net}})
é implantado nos nós alvos pelo EE e
coleta valores de uso de CPU, memória e disco dos nós.

\section{Especificação da composição de serviços}
\label{sec:spec}

O \ee recebe de seus clientes a especificação da composição na forma 
de uma descrição arquitetural com as informações necessárias e suficientes para 
que se possa realizar a implantação da composição. 
O EE também devolve ao seu cliente informações sobre o resultado da implantação, 
em especial as localizações de acesso aos serviços. As descrições da composição e de sua 
especificação são feitas com uma \emph{linguagens de descrição arquitetural} (ADL), 
assim como a dos trabalhos vistos no Capítulo~\ref{cap:relacionados}. 
A nossa ADL consiste na descrição de objetos relacionados entre si seguindo 
a estrutura de classes apresentada na Figura~\ref{fig:adl}. 
Em nossa implementação, essa descrição é concretizada com representações em XML, 
que são trocadas entre o EE e seu cliente. 
A descrição detalhada de cada atributo e o \emph{schema} XML da linguagem
são apresentados no \userguide.

\begin{figure}[!h]
  \centering
  \includegraphics[width=.90\textwidth]{adl.pdf} 
  \caption{Estrutura da descrição arquitetural de uma coreografia. \todo{atualizar}}
  \label{fig:adl} 
\end{figure}

A especificação da coreografia fornece todas as informações para a implantação da composição,
possibilitando que o implantador descreva em alto-nível apenas \emph{o que} deve ser implantado,
e não os detalhes de implementação de \emph{como} deve ser implantado.
Essa última situação, o \emph{como} detalhado, é situação típica na escrita de scripts de implantação.

Em nossa ADL, para cada serviço, especifica-se de onde o pacote do serviço pode ser baixado, 
qual o tipo do pacote (WAR, JAR, etc.), quantas réplicas devem ser implantadas, etc.
Pode-se especificar também a existência de serviços
de terceiros que já estão disponíveis na Internet e que devem
ser consumidos por serviços da composição.

O implantador pode escrever a especificação da coreografia diretamente em XML
ou utilizando objetos Java (POJOs).
A Listagem~\ref{lst:service_spec} apresenta um trecho da especificação escrita em Java,
no qual um dos serviços participantes é definido,
incluindo sua dependência de outro serviço participante.

\lstset{
language=Java,
}

{\scriptsize
\begin{lstlisting}[breaklines, caption={Trecho da especificação de uma coreografia.}, label={lst:service_spec}]
airportBusCompanySpec =
  new DeployableServiceSpec(AIRPORT_BUS_COMPANY, ServiceType.SOAP, PackageType.COMMAND_LINE, resourceImpact, serviceVersion, AIRPORT_BUS_COMPANY_JAR_URL, AIRPORT_BUS_COMPANY_PORT, AIRPORT_BUS_COMPANY, numberOfReplicas);
airportBusCompanySpec.setRoles(
  Collections.singletonList(AIRPORT_BUS_COMPANY));
airportBusCompanySpec.addDependency(
  new ServiceDependency(AIRPORT, AIRPORT_ENDPOINT));
\end{lstlisting}
}

\section{Ligação entre serviços}
\label{sec:ligacao}

Em uma composição de serviços alguns serviços se comunicam com outros serviços para implementar o fluxo de negócio.
Quando um serviço $A$ invoca um serviço $B$, dizemos que o serviço $A$ depende do serviço $B$. 
Dizemos também que $A$ é \emph{dependente} de $B$, enquanto que $B$ é \emph{dependência} de $A$,
ou ainda que $A$ é \emph{consumidor} de $B$, enquanto que $B$ é \emph{provedor} de $A$.
Para que uma coreografia funcione, cada serviço precisa saber o endereço de suas dependências,
e o processo pelo qual os serviços recebem os endereços de suas dependências é denominado \emph{ligação}.

Segundo Dearle~\cite{Dearle2007PastPresentFuture}, componentes podem ser ligados entre si em vários momentos: compilação, montagem, configuração e execução. Em nosso contexto, a ligação deve ser efetuada necessariamente em tempo de execução, pois é somente nesse momento que teremos os endereços completos dos serviços implantados. Uma das possibilidades apontadas por Dearle para efetivação da ligação em tempo de execução é a utilização do padrão de injeção de dependência, conforme introduzido por Fowler~\cite{Fowler2004Inversion}. A injeção de dependências é utilizada em contêineres como o Springer\footnote{\url{http://www.springer.org}}, no qual o middleware passa ao componente referências de suas dependências. No entanto, Dearle ainda alega que há uma falta de arcabouços para a aplicação da injeção de dependência de forma distribuída.

A solução adotada no \ee para possibilitar a ligação entre serviços envolve a utilização do middleware para a passagem de endereços dos serviços implantados aos seus consumidores. Essa solução consiste na aplicação do padrão de injeção de dependência de forma distribuída, e é similar ao que foi feito nos trabalhos sobre a linguagem Darwin~\cite{Magee1996Dynamic, Magee1994Regis}. 
Note que nessa solução, a ``inteligência'' em determinar quais serviços satisfazem as necessidades de outros serviços está na camada que produz a entrada do EE.
As dependências entre os serviços são definidas na especificação da coreografia,
pela lista de objetos \textsf{ServiceDependency} pertencentes a um \textsf{ServiceSpec}.
Cada serviço na coreografia que possua dependências deve implementar uma operação denominada \texttt{setInvocationAddress}. 
Essa operação, por nós padronizada, recebe como argumentos as seguintes informações sobre a dependência: 

\begin{description}

\item [Papel:] é um nome associado a uma interface, ou seja, define as operações fornecidas por um serviço. A associação entre o nome e 
a interface deve ser previamente acordada pelas organizações participantes da coreografia e a implementação do serviço
deve estar ciente dos nomes e interfaces de suas dependências.

\item [Nome:] é um nome que identifica univocamente o serviço no contexto de uma coreografia. Serve para que o serviço dependente possa 
diferenciar serviços com o mesmo papel. Exemplo: se um serviço de pesquisa de preços utiliza serviços do papel \emph{supermercado},
ele utilizará o nome do serviço para diferenciar os serviços de supermercados diferentes. Com essa semântica, o EE pode atualizar
os endereços de um supermercado com uma nova chamada ao \texttt{setInvocationAddress}, sem que o serviço dependente considere
que se trata de um novo supermercado.

\item [Endereços:] são as URIs das réplicas pelas quais pode-se acessar a dependência.

\end{description}

Assim, em uma coreografia em que, por exemplo, um serviço de agência de viagem dependa do serviço de uma companhia aérea, o EE executará a seguinte invocação ao serviço da agência de viagens : \texttt{setInvocationAddress('Companhia Aérea', 'Nimbus Airline', [ 'http://192.168.56.107:8080/nimbus/ws/' ])}. 

A descrição fornecida até aqui é abstrata e independente de tecnologia.
A definição exata da assinatura da operação deve ser definida de acordo com a tecnologia utilizada.
A versão atual do EE já define essa assinatura para serviços SOAP.
Para detalhes, ver o guia do usuário (Apêndice~\ref{ape:user_guide}).

Apesar dos benefícios dessa solução, Dearle~\cite{Dearle2007PastPresentFuture} também alerta sobre a desvantagem em forçar componentes a aderirem convenções de codificação impostas pelo middleware, o que poderia restringir o serviço a uma determinada linguagem de programação ou a algum middleware específico. Reconhecemos que esse problema existe em nossa solução, mas acreditamos que o desenho adotado ameniza os problemas levantados, pois tudo o que o serviço é obrigado a fazer é implementar a operação \texttt{setInvocationAddress} e conhecer os papeis de suas dependências, o que implica em conhecer a interface sintática de cada papel. Dessa forma, nossa solução não restringe o serviço a nenhuma linguagem e não impede a utilização do serviço em outro middleware.

\section{Mapeamento dos serviços na infraestrutura alvo}
\label{sec:mapeamento}

Em algum momento do processo de implantação é preciso definir em que nó cada instância de serviço será hospedado.
Chamamos por \emph{mapeamento}, ou seleção de nós, essa fase do processo de implantação.
Na forma mais simples de seleção de nó, o IP do nó alvo é definido estaticamente no script de implantação do serviço.
O trabalho de Magee e Kramer~\cite{Magee1997Corba} apresenta a seleção de nós em função da utilização de CPUs nos nós existentes, não havendo possibilidade de utilização de outros critérios, como memória, disco, custo etc. Nos sistemas apresentados por Dolstra et al.~\cite{Dolstra2005Configuration} e Balter et al.~\cite{Balter1998Olan} é preciso que a distribuição dos serviços seja especificada com o uso dos IPs das máquinas nas quais os serviços devem ser implantados, o que não é possível em um ambiente de nuvem. Por fim, o \emph{broker} apresentado por Watson et al. é o componente que mais se assemelha ao nosso NodeSelector, pois os autores deixam claro que várias implementações diferentes são possíveis, considerando-se diferentes tipo de requisitos e diferentes fontes de monitoramento. Como a escolha é feita em tempo de execução do serviço, seria também possível uma seleção que independa de IPs estabelecidos em tempo de projeto. No entanto, os autores não explicam como os usuários de seu sistema, os provedores de infraestrutura, deveriam proceder para criar seus próprios \emph{brokers} personalizados.

Para avançar em relação às limitações dos trabalhos anteriormente citados, 
a seleção de nós no \ee
considera os requisitos de dinamicidade do ambiente de nuvem, que nos impede de conhecer os IPs das máquinas 
em tempo de desenvolvimento ou configuração do script de implantação.
O EE utiliza um seletor de nós automatizado que escolhe em tempo implantação os nós alvos para um dado serviço.
A escolha de uma política ótima para o seletor é assunto de diversas pesquisas.
Portanto, adotamos aqui uma abordagem extensível, com o fornecimento inicial de políticas como
``sempre cria um novo nó'' ou ``cria nós até um limite, e depois faz rodízio entre eles''.

\section{Interface do \ee}
\label{sec:interface}

Os clientes do \ee utilizam suas funcionalidades por meio de uma API REST, que é descrita nesta seção. 
Por se tratar de uma API REST, o cliente pode ser implementado em qualquer linguagem 
e ambiente que possua alguma biblioteca HTTP. 
Também disponibilizamos um cliente na forma de uma biblioteca na linguagem Java, 
tornando o uso do EE ainda mais simples para os usuários da linguagem Java, 
atualmente uma das mais utilizadas do mercado. 
Seguimos agora com uma descrição de alto nível de cada uma das operações disponíveis 
na API REST do EE. Detalhes da API, como os códigos de status HTTP retornados, 
são fornecidos no guia do usuário (Apêndice~\ref{ape:user_guide}).

\begin{description}

\item [Criar coreografia:] registra a especificação de uma coreografia no EE. 
Essa especificação é a descrição arquitetural da coreografia, 
estruturada de acordo com a classe \textsf{ChorSpec} (Figura~\ref{fig:adl}). 
Essa operação não realiza a implantação da coreografia.

\item [Obter coreografia:] obtém informações sobre uma coreografia registrada no EE. 
Essas informações referem-se à especificação da coreografia e ao estado da implantação 
de seus serviços, como os nós em que os serviços foram implantados, 
no caso de a implantação já ter sido realizada.

\item [Encenar coreografia:] realiza a implantação de uma coreografia já registrada no EE. 
Ao fim do processo, detalhes do resultado da implantação são retornados de forma estruturada 
de acordo com a classe \textsf{Choreography} (Figura~\ref{fig:adl}).
A implementação dessa operação deve possuir duas importantes propriedades: 
1) a falha na encenação de parte da coreografia não deve interromper a encenação do resto da coreografia; 
2) a operação deve ser \emph{idempotente}, ou seja, uma nova requisição para a encenação da mesma 
coreografia não deve reimplantar os serviços já implantados, 
mas somente aqueles cujas implantações falharam na última execução. 
Para que serviços sejam atualizados, é preciso utilizar um novo valor no atributo ``versão'' da especificação do serviço.

\item [Atualizar coreografia:] registra uma nova versão de uma coreografia no EE. 
Os serviços atualizados na nova versão da coreografia devem possuir 
um novo número de versão em suas especificações. 
Essa operação, assim como a criação da coreografia, não implanta a nova coreografia. 
Para isso, é preciso invocar novamente a operação de encenação.

A atualização de serviços não é o foco de nosso trabalho.
Dessa forma, em nosso trabalho a atualização dos serviços será feita da forma mais simples possível: 
apenas substituindo o serviço existente por sua nova versão. 
Contudo, tal procedimento pode provocar falhas na comunicação entre os serviços de uma coreografia. 
Vários trabalhos \cite{Kramer1990Philosophers, Vandewoude2007Tranquility, Xiaoxing2011VersionConsistent} 
estudam o processo de atualização dinâmica, pelo qual as conversações correntes 
são preservadas durante a atualização de um serviço. 
Embora não esteja no escopo de nosso trabalho, esperamos que a arquitetura do EE possa ser 
evoluída para que a operação de atualização de coreografia utilize procedimentos seguros de 
atualização dinâmica, dentre os quais destacamos a proposta de Xiaoxing et al~\cite{Xiaoxing2011VersionConsistent}.

\end{description}

Na Listagem~\ref{lst:java_chor_enactment} fornecemos um exemplo de 
um programa Java invocando o EE para implantar uma coreografia.
Nesse exemplo, a classe \textsf{MyChorSpec} está escondendo a 
especificação da coreografia.

\begin{lstlisting}[breaklines, caption={Programa Java que invoca o \ee para implantar uma coreografia.}, label={lst:java_chor_enactment}]
public class Enactment {

    public static void main(String[] args) throws EnactmentException, ChoreographyNotFoundException {

        final String EE_URI = "http://localhost:9102/enactmentengine";
        EnactmentEngine ee = new EnactmentEngineClient(EE_URI);
        ChoreographySpec chorSpec = MyChorSpec.getChorSpec();

        String chorId = ee.createChoreography(chorSpec);
        Choreography chor = ee.enactChoreography(chorId);

        System.out.println(chor); // vamos ver o que aconteceu...
    }
}
\end{lstlisting}


\section{Pontos de extensão}
\label{sec:extensao}

Para lidar com as particularidades do ambiente de cada organização, o Enactment Engine fornece alguns pontos de extensão. Esses pontos de extensão são classes que desenvolvedores devem escrever na linguagem Java e que, de acordo com as configurações do sistema, poderão ser executadas pelo arcabouço.
Neste capítulo descreveremos os pontos de extensão de nosso middleware, 
mostrando as interface associadas a cada um deles.
Para mais detalhes sobre todos os passos necessários para implementar
uma extensão, verificar o guia do usuário (Apêndice~\ref{ape:user_guide}).

\begin{description}

\item [Provedor de infraestrutura:] implementando a interface \textsf{CloudProvider} (Listagem~\ref{lst:cloud_provider}) 
é possível acrescentar ao EE o suporte a novos provedores de infraestrutura. 
Atualmente o EE suporta o serviço EC2 do AWS e o OpenStack como provedores de infraestrutura.
Cada um deles possui sua própria implementação de \textsf{CloudProvider}.

\begin{lstlisting}[frame=trbl, label=lst:cloud_provider, caption=Interface CloudProvider.]
public interface CloudProvider {

    public String getCloudProviderName();

    public CloudNode createNode(NodeSpec nodeSpec) throws NodeNotCreatedException;

    public CloudNode getNode(String nodeId) throws NodeNotFoundException;

    public List<CloudNode> getNodes();

    public void destroyNode(String id) throws NodeNotDestroyed, NodeNotFoundException;

    public CloudNode createOrUseExistingNode(NodeSpec nodeSpec) throws NodeNotCreatedException;

    public void setCloudConfiguration(CloudConfiguration cloudConfiguration);

}
\end{lstlisting}

Os métodos da interface \textsf{CloudProvider} referem-se basicamente às operações de CRUD de máquinas virtuais
em uma infraestrutura de nuvem. Além disso, a implementação pode acessar configurações específicas 
através do objeto \texttt{cloudConfiguration}. Tais configurações podem incluir 
credenciais de acesso de uma conta de nuvem (quem paga pelos nós), tipo das instâncias de VMs a serem criadas (afeta preço),
chave de acesso aos nós criados, etc. A Listagem~\ref{lst:cloud_configuration} apresenta um exemplo de configurações
fornecidas à implementação \textsf{AmazonCloudProvider}. 
Essas informações são definida pelo administrador em um arquivo de configuração do EE.

\begin{lstlisting}[frame=trbl, label=lst:cloud_configuration, caption=Configuração do \textsf{AmazonCloudProvider}.]
LEO_AWS_ACCOUNT.CLOUD_PROVIDER=AWS
LEO_AWS_ACCOUNT.AMAZON_ACCESS_KEY_ID=secret!
LEO_AWS_ACCOUNT.AMAZON_SECRET_KEY=secret_too!
LEO_AWS_ACCOUNT.AMAZON_KEY_PAIR=leofl
LEO_AWS_ACCOUNT.AMAZON_PRIVATE_SSH_KEY=/home/leonardo/.ssh/leoflaws.pem
LEO_AWS_ACCOUNT.AMAZON_IMAGE_ID=us-east-1/ami-3337675a
LEO_AWS_ACCOUNT.AMAZON_INSTANCE_TYPE=m1.medium
\end{lstlisting}
 
Para facilitar o desenvolvimento de novas implementações,
nós fornecemos uma implementação base, a classe \textsf{JCloudsCloudProvider}.
Ela utiliza a biblioteca JClouds\footnote{\url{http://jclouds.incubator.apache.org/}},
que já é apta a acessar uma ampla gama de provedores de infraestrutura disponíveis no mercado.
Essa implementação base foi utilizada para a implementação das classes 
\textsf{AmazonCloudProvider} e \textsf{OpenStackKeyStoneCloudProvider},
que contaram, respectivamente, com 79 e 96 linhas de código-fonte.


\item [Política de seleção de nós:] a implementação da interface \textsf{NodeSelector} (Listagem~\ref{lst:node_selector})
define uma nova política de alocação de serviços em nós da nuvem, que pode levar em conta os requisitos não-funcionais do serviço e 
propriedades dos nós à disposição.
Algumas políticas já fornecidas são ``sempre cria um novo nó'' e 
``cria novos nós até um certo limite, depois faz rodízio entre eles''.

\begin{lstlisting}[frame=trbl, label=lst:node_selector, caption=Interface NodeSelector acompanhada de sua classe pai Selector.]
public interface NodeSelector extends Selector<CloudNode, DeployableServiceSpec> {
}

public interface Selector<T, R> {
    public List<T> select(R requirements, int objectsQuantity) throws NotSelectedException;
}
\end{lstlisting}

As implementações de \textsf{NodeSelector} devem criar novos nós ou devolver nós já cadastrados no EE.
Os requisitos não-funcionais podem ser acessados pelo objeto \texttt{deployableServiceSpec} fornecido pelo
middleware à implementação do \textsf{NodeSelector}.
A implementação deve tomar especial cuidado com concorrência, já que o EE mantêm apenas uma instância
por tipo de \textsf{NodeSelector}. Essa característica é importante para que políticas como
rodízio de nós funcionem adequadamente.


\item [Tipos de pacotes de serviços:] um serviço pode ser distribuído por diferentes tipos de pacotes, como em um JAR ou em um WAR, por 
exemplo. Como existem muitas outras opções, é preciso que esse seja um ponto de flexibilidade. Para cada novo tipo de pacote, escreve-se 
um modelo de um \emph{cookbook} Chef que implemente a preparação e a inicialização do serviço. Um \emph{cookbook} possui vários 
arquivos, mas os principais são os arquivos da \emph{receita}, que é o script de instalação em si, e o arquivo que define \emph
{atributos} a serem usados nas receitas. A Listagem~\ref{lst:recipe_template} mostra a receita do \emph{cookbook} modelo
para implantação de WARs, enquanto que a Listagem~\ref{lst:attributes_template} mostra o arquivo de atributos do mesmo \emph{cookbook}.

\begin{lstlisting}[frame=trbl, label=lst:recipe_template, caption=Receita modelo para a implantação de WARs.]
include_recipe "apt" 
include_recipe "tomcat::choreos"

remote_file "war_file" do
        source "#{node['CHOReOSData']['serviceData']['$NAME']['PackageURL']}"
        path "#{node['tomcat']['webapp_dir']}/$NAME.war"
        mode "0755"
        action :create_if_missing
end

file "#{node['tomcat']['webapp_dir']}/$NAME.war" do
        action :nothing
end
\end{lstlisting}

\begin{lstlisting}[frame=trbl, label=lst:attributes_template, caption=Arquivo modelo de atributos para a implantação de WARs.]
default['CHOReOSData']['serviceData']['$NAME']['PackageURL'] = "$PACKAGE_URL"
\end{lstlisting}

Os arquivos listados acima são modelos não executáveis, uma vez que apenas em tempo de implantação 
os símbolos \emph{\$NAME} e \emph{\$PACKAGE\_URL} serão substituídos por valores adequados.
Essa substituição é feita pelo próprio EE.
Ou seja, criar um novo modelo de \emph{cookbok} para o EE significa simplesmente criar um novo \emph{cookbok} Chef
utilizando adequadamente os símbolos \emph{\$NAME} e \emph{\$PACKAGE\_URL}.
O símbolo \emph{\$PACKAGE\_URL} será substituído pela URL do pacote do serviço,
enquanto que o \emph{\$NAME} será substituído por uma identificação única dentro do EE.


\item [Tipos de serviços:] a ligação entre serviços de uma composição depende da passagem de endereços que é feita do \ee para os 
serviços. Para isso, o EE precisa invocar a operação \texttt{setInvocationAddres} dos serviços. A implementação de tal invocação dar-se-
á de forma diferente de acordo com o tipo de tecnologia de serviço empregada (SOAP ou REST, por exemplo). 
A implementação da interface \textsf{ContextSender} define como a operação \texttt{setInovcationAddress} é invocada. 
Atualmente o EE possui uma implementação de \textsf{ContextSender}, utilizada para serviços SOAP.
Nota-se que para cada nova implementação, é preciso definir uma convenção para a assinatura sintática da operação \texttt
{setInvocationAddres}.

\begin{lstlisting}[frame=trbl, label=lst:context_sender, caption=Interface ContextSender.]
public interface ContextSender {
    public void sendContext(String serviceEndpoint, 
                            String partnerRole, 
                            String partnerName, 
                            List<String> partnerEndpoints) throws ContextNotSentException;
}
\end{lstlisting}

\end{description}


\section{Aspectos gerais de implementação}

Nesta seção descreveremos alguns detalhes sobre a implementação do \ee que 
podem ser especialmente úteis a eventuais desenvolvedores de nosso middleware.

\begin{description}

\item [Linguagem:] 

O \ee é desenvolvido com a linguagem Java 6. 
Durante o desenvolvimento utilizamos como ambiente de execução
a JVM OpenJDK 7. O EE é compilado com o Maven 3.

\item [Chef-solo:] 

O Chef é a pedra angular sobre a qual construímos o \ee.
De certa forma, o EE é uma camada de abstração que facilita o uso do Chef.
A versão utilizada do Chef-Solo é a 11.8.0.
Em versões anteriores do EE, utilizamos o Chef Server,
mas acabamos por abandona-lo, devido ao grande gargalo na escalabilidade
que ele gerava, além do pouco benefício funcional que ele agregava.
As receitas Chef são escritas em uma Linguagem Específica de Domínio (DSL) 
que permite a livre
utilização da linguagem Ruby, mas que possui construtos
específicos para as tarefas de implantação, visando proporcionar
principalmente mecanismos de idempotência. Um exemplo pode ser
observado na Listagem~\ref{lst:chef_idempotente}, no qual
se especifica o download de um arquivo que será
baixado somente caso ele ainda não exista no sistema alvo.

\begin{lstlisting}[frame=trbl, label=lst:chef_idempotente, caption=Trecho de receita Chef que ilustra uso de idempotência.]
remote_file "#{node['easyesb']['downloaded_file']}" do
  source "#{node['easyesb']['url']}"
  action :create_if_missing
end
\end{lstlisting}

\item [Apache CXF:]

Uma das principais bibliotecas utilizadas pelo EE é o Apache CXF,
que traz uma série de utilidades para o desenvolvimento de serviços em Java,
dentre elas a implementação do padrão JAX-RS, voltado ao desenvolvimento de serviços REST.

\item [Configuração por imagem:]

Na gerência de configuração de ambientes, há duas abordagens, 
já discutidas na Seção~\ref{sec:cloud}, sobre como configurar um ambiente:
1) utilização de imagem de disco já contendo serviço a ser implantado
e 2) utilização de scripts para instalação do serviço.
Enquanto a primeira abordagem prima pelo desempenho,
a segunda opção oferece maior flexibilidade e facilidade de evolução.
A abordagem padrão no \ee é se utilizar a configuração por scripts (gerados pelo EE).
Mas o EE fornece a opção de que o administrador configure qual imagem será
utilizada para criar os nós alvos.
Isso possibilita que o administrador configure uma imagem 
que já contenha o middleware sobre o qual os serviços serão executados.
Assim, se o administrador sabe que o EE será utilizado para implantar WARs,
ele pode configurar uma imagem que já contenha o Tomcat instalado.
Essa abordagem reduz o tempo de implantação.

\item [Testes:] 

Os testes de unidade do \ee podem ser executados com o comando \texttt{mvn test}.
Embora o EE contenha vários testes de unidade e isso seja fundamental,
há uma limitação considerável desses testes, já que executar comandos que
provoquem efeitos colaterais no sistema operacional não seja adequado
em testes de unidade. Tais ``efeitos colaterais'' são sempre provocados
durante a execução das receitas Chef.

Por isso o EE possui também vários testes de \emph{integração} automatizados,
no qual máquinas virtuais são utilizados para a execução de testes nos
quais o EE possa interagir com um sistema operacional.
Esses testes incluem a implantação completa de coreografias.
Embora esses testes sejam importantes para validar o correto funcionamento do sistema,
eles são muito custosos, tanto em termos financeiros quanto de tempo,
uma vez que máquinas virtuais são criadas durante esses testes.

De nossa experiência neste trabalho, acreditamos que
o desenvolvimento de tecnologias de máquinas virtuais
voltadas para o ambiente de teste de aceitação,
de forma que as máquinas sejam criadas mais rapidamente,
seja uma contribuição relevante para a prática de desenvolvimento de software.

\item [Software livre:] por fim, todos as bibliotecas e sub-sistemas
utilizados pelo \ee são software livre.

\end{description}

\section{Discussão: auxiliando implantações em grande escala}

Nesta seção discutiremos como as características arquiteturais e de implementação do \ee
impactam na implantação de composições de serviço de grande escala.
Explicaremos como o EE contribui para a resolução de cada um dos desafios
apresentados na Seção~\ref{sec:desafios}.
Durante a discussão destacaremos como uma solução de middleware traz vantagens
sobre abordagens \emph{ad-hoc} de implantação em nosso contexto.
Essa discussão, suportada pelo efetivo funcionamento do EE demonstrado por sua avaliação
(Capítulo~\ref{cap:avaliacao}), fornece também subsídios para a implementação de novos sistemas
de implantação de grande escala, mesmo que não voltados a composições de serviços,
e até mesmo para soluções \emph{ad-hoc}.

\begin{description}

\item [Processo:]

Tornar a implantação de sistemas ``\emph{Internet-scale}'' processos totalmente automatizados
é necessário para que a implantação se torne testável, flexível e confiável~\cite{Hamilton2007InternetScale},
conforme discutido na Seção~\ref{sec:implantacao}.
O EE possibilita a automação do processo de implantação
graças a sua interface remota (REST), que recebe a especificação
da composição a ser implantada e devolve o resultado do processo.
Embora uma interface gráfica para a implantação de composições seja viável,
tal opção não favorece a implantação automatizada,
e por isso não foi priorizada em nosso trabalho.

O uso de uma especificação declarativa,
como já utilizado em outros trabalhos~\cite{Balter1998Olan,Magee1996Dynamic},
também facilita o desenvolvimento do script de implantação
para cada nova composição a ser implantada.
Isso ocorre porque com uso de uma linguagem declarativa o implantador descreve em alto nível apenas
\emph{o que} deve ser implantado, e não os detalhes de \emph{como} deve ser implantado.
O uso de linguagens declarativas requer algum tipo de middleware que interprete
a descrição declarativa, executando as ações adequadas.
Portanto, soluções \emph{ad-hoc} dificilmente usariam linguagens declarativas,
sendo em geral orientadas ao uso de scripts.

O EE segue a tendência atual na implantação de sistemas de grande escala, que é o uso
de recursos elásticos possibilitados pela computação em nuvem.
Recursos virtualizados fornecidos pela nuvem potencializam
a automação do processo de implantação~\cite{Humble2011Continuous}.
Diferentemente dos cenários estudados em trabalhos anteriores sobre
implantação de sistemas baseados em componentes~\cite{Balter1998Olan,Magee1996Dynamic},
em uma infraestrutura de nuvem os nós alvos são mais dinâmicos. Não é possível conhecer os endereços IPs
dos nós alvos quando se está escrevendo a especificação da composição a ser implantada.
A ligação entre serviços deve ser feita em tempo de execução, o que o EE faz via \texttt{setInvocationAddress},
e a política de alocação de nós deve ser flexível, i.e.,
um serviço não deve ser alocado a um IP estático antes do tempo de implantação.
O EE possibilita que políticas de alocação de nós
escolham em tempo de implantação em que nós um serviço deve ser implantado,
considerando inclusive o casamento de requisitos não-funcionais do serviço
com características dos nós disponíveis.

\item [Falhas de terceiros:]

Seguindo recomendações gerais feitas por Nygard~\cite{Nygard2009Release},
adotamos no \ee uma abordagem simples para tratar falhas externas.
A lógica de invocação a sistemas externos foi encapsulada em uma classe, 
chamada \textsf{Invoker}, que foi usada de forma disciplinada pelo projeto.
Toda vez que se deve acessar um sistema externo, utiliza-se um \emph{invoker}.
Nosso \textsf{Invoker} recebe os seguintes parâmetros:
uma \emph{tarefa}, que é uma rotina que se comunicará com algum sistema externo,
a quantidade de \emph{tentativas} para executar a tarefa,
o \emph{timeout} de cada tentativa, e um \emph{intervalo} entre as tentativas.

Uma instância do \textsf{Invoker} deve ser configurada 
de acordo com sua tarefa (por exemplo, nós descobrimos que três tentativas
não é o suficiente para transferência de arquivos por SCP).
Em vez de ter esses valores fixados no código-fonte, eles são explicitamente
ajustados em arquivos de configuração.
Desta forma, pode-se facilmente ajustar esses valores de acordo com 
as características do ambiente alvo.
Portanto, essa abordagem é também uma estratégia para colaborar 
com a heterogeneidade de plataformas e tecnologias.
A classe \textsf{Invoker} pode ser decorada\footnote{Ver padrão de projeto \emph{decorator}~\cite{GoF1995Patterns}.} 
para adaptar dinamicamente valores de timeouts 
baseando-se em heurísticas definidas programaticamente 
que utilizem o histórico de execução dos \emph{invokers}.

O EE garante a utilização correta e disciplinada dos \emph{invokers} nos momentos adequados e necessários.
Isso fornece uma robustez mais facilmente proporcionada por sistemas de middleware,
nos quais interesses transversais podem ser implementados sem que o desenvolvedor da aplicação 
(o script de implantação em nosso caso) tenha que se preocupar com isso.

O EE adota uma estratégia particular par lidar com falhas durante a criação de novas VMs.
Quando uma requisição chega, o EE tenta criar um novo nó.
Se a criação falha ou demora muito, um nó já criado é recuperado de uma reserva de nós ociosos.
Essa estratégia evita que se tenha que esperar novamente pelo tempo de se criar um novo nó.
A capacidade inicial da reserva é definida por configuração
e ela é preenchida cada vez que a criação de um nó é requisitada.
Se o tamanho da reserva é reduzido e alcança um dado limite,
a capacidade é aumentada, de forma a tentar evitar uma situação futura
de se encontrar uma reserva vazia em um momento de necessidade.

A abordagem da reserva impõe um custo extra de se manter algumas VMs a mais
em execução (em um estado ocioso). Contudo, esse problema é tratado
pelo EE por um algoritmo de gerenciamento distribuído em cada nó:
se o nó está em um estado ocioso por $N-1$ minutos, onde $N$ é um limite
de tempo que implica custo adicional, o nó envia ao EE um pedido para 
sua própria destruição. Assim, depois de um tempo de inatividade no EE,
a reserva se torna vazia em algum momento, sendo preenchida novamente
somente quando chegam novas requisições de criação de nós.
%This distributed approach alleviates the need to have the \ee periodically check
%the status of the machines to decide whether they should be removed.

Considerando que o tempo de criação de um nó é bem maior que o tempo de inicialização (\emph{boot})
desse nó, uma melhoria a ser feita na reserva de nós ociosos é manter o nó ocioso desligado
até o momento de uso, uma vez que provedores de infraestrutura, como a Amazon,
costumam não cobrar por máquinas desligadas.
Essa abordagem pode diminuir um pouco o desempenho da reserva de nós,
mas irá economizar mais recursos.

Outra prática importante relacionada a tolerância a falhas é a 
\emph{degradação suave}~\cite{Brewer2001GiantScale,Hamilton2007InternetScale}.
Em nosso contexto, degradação suave significa que se um serviço não foi 
implantado apropriadamente, não é aceitável que o processo de implantação
de toda a composição seja interrompido.
Com o EE, se algum serviço não é implantado, o processo de implantação continua,
e a resposta do EE fornece informações sobre os problemas ocorridos,
possibilitando ações de recuperação.

Contudo, é importante destacar que a responsabilidade pela degradação suave
debe ser compartilhada com a implementação dos serviços, uma vez que cada serviço
debe saber como se comportar na ausência de uma ou mais de suas dependências.
De outra forma, cada serviço se tornaria um \emph{ponto de falha único} na composição,
o que é altamente indesejável.

\item [Disponibilidade:]

A especificação de um serviço na ADL do \ee possibilita a definição da quantidade de réplicas
de um serviço a ser implantado pelo EE.
Essa quantidade inicial de réplicas pode ser alterada pelo implantador em tempo de execução
com a atualização da especificação da coreografia.
A definição da quantidade adequada de réplicas, definida pelo implantador, permite não só uma melhora
de desempenho, mas também um aumento na disponibilidade do serviço, já que uma falha em uma réplica
específica não afeta as outras réplicas disponíveis.

Por questões de simplificação, em nosso trabalho omitimos a relação que serviços possuem com bancos de dados.
Dessa forma, é importante que versões futuras do EE contemplem a automação da implantação de bancos de dados
a serem utilizados pelos serviços implantados. Nesse estágio, deverá ser considerado também a replicação
do banco de dados, e que os dados são utilizados simultaneamente por várias réplicas do serviço.

\item [Escalabilidade:]

Embora o conhecimento de programação concorrente para implementar
um processo de implantação escalável seja básico (dentro do contexto de computação concorrente),
programação concorrente por si própria é difícil e propensa a erros.
Muitas vezes, linguagens de scripts não oferecem um bom suporte à programação concorrente.
O tratamento adequado de falhas de terceiros também é um requisito importante
para a obtenção de um sistema escalável.
Portanto, implementar concorrência e tratamento a falhas na camada de middlware
é um passo significativo em facilitar a implementação efetiva de um
processo de implantação escalável.
No Capítulo~\ref{cap:avaliacao} avaliaremos em detalhes a escalabilidade fornecida pelo \ee.

\item [Heterogeneidade:]

Na Seção~\ref{sec:extensao} apresentamos os pontos de extensão do \ee,
que permitem mais facilmente equipá-lo para diversos provedores de infraestrutura
e tecnologias de desenvolvimento e empacotamento de serviços.
Essa flexibilidade ajuda a superar
as atuais limitações de soluções de Plataformas como um Serviço
que restrigem as opções tecnológicas disponíveis aos desenvolvedores de aplicações.
Essas restrições normalmente se aplicam justamente sobre
provedor de infraestruturas e a linguagem de programação da aplicação.

Suportar variações de um padrão é um desafio para sistemas de middleware.
Adequar um middleware para a particularidade de uma aplicação pode não ser fácil.
No suporte a diferentes tecnologias, as abordagens \emph{ad-hoc} encontram realmente um espaço de importância.
No entanto, uma vez que a adequação para uma nova tecnologia seja feita no middleware,
pode-se aplicar mais facilmente a melhoria para diferentes aplicações utilizando essa
mesma nova tecnologia.

\item [Múltiplas organizações:]

O \ee possui dois principais mecanismos para implantar composições cujos serviços
pertencem a diferentes organizações.
O primeiro mecanismo é a definição da ``conta de nuvem'' a ser usada na implantação de um serviço.
Essa definição é feita na especificação do serviço e deve bater com configurações
previamente feitas pelo administrador no EE.
Uma ``conta de nuvem'' não indica apenas a nuvem alvo (Amazon, por exemplo),
mas também que vai pagar pela infraestrutura (qual conta da Amazon será utilizada, por exemplo).
Uma vez que os serviços de cada organização sejam configurados para serem implantados
nas contas de nuvem adequadas, o EE irá implantar adequadamente uma composição
multi-organizacional.
No entanto essa abordagem ainda apresenta limitações sérias no quesito de segurança,
pois a configuração da conta de nuvem deve ser fornecida ao administrador do EE,
que seria uma das organizações ou um terceiro.
Esse e outros problemas surgem do fato que diferentes organizações teriam que
compartilhar uma mesma instância do EE.

O segundo mecanismo é a utilização da entidade \emph{serviço legado} na especificação da composição.
O serviço legado é um serviço já existente e disponível na Internet, e que portanto
não será implantado pelo EE.
A utilidade em utilizar esse mecanismo está na fase de ligação
entre serviços, pois o EE irá fornecer
aos serviços implantados os endereços dos serviços legados declarados como suas dependências.
A maior limitação dessa abordagem é a dificuldade em se lidar com a alteração de URIs
dos serviços legados.
Quando isso ocorre, uma nova especificação da composição deve ser feita e enviada ao EE,
mas o problema é saber \emph{quando} isso deve ser feito.

Considerando as limitações dos mecanismos até aqui implementados,
divisamos como importante trabalho futuro uma arquitetura de federação entre instâncias do EE.
Caso um serviço $S_A$, implantado com o EE pela organização $O_A$, dependa de um serviço legado $B$,
também implantado com o EE, mas para a organização $O_B$, a instância do EE em $O_B$ poderia
manter a instância do EE em $O_A$ informada sobre o estado de $S_B$.
Para que essa funcionalidade seja implementada é preciso projetar um protocolo
de comunicação entre instâncias do EE.

Nesse estágio proposto (federação dos sistemas implantadores de cada organização) uma abordagem
orientada a middleware se torna importante por questão de padronização.
Abordagens \emph{ad-hoc} deveriam ser desenvolvidas de forma coordenada entre as diferentes organizações,
o que seria mais custoso do que a adoção de uma plataforma comum.

\item [Adaptabilidade:]

O \ee por si só não garante que uma composição será autonômica ou auto-adaptativa.
Contudo, ele fornece suporte para o desenvolvimento de tais sistemas.

Sistemas auto-adaptativos e autonômicos precisam estar cientes
e ter pleno controle das atividades de implantação.
Para empoderar tais sistemas, o EE fornece informação e controle
das seguintes funcionalidades:

\begin{itemize}
\item atualização das composições;
\item migração de serviços;
\item replicação de serviços;
\item implantação de infraestrutura de monitoramento.
\end{itemize}

Atualização de composições de serviços podem ser necessárias quando
as regras de negócio ou os requisitos não-funcionais mudam.
O EE permite, por uma API REST, a adição, remoção e reconfiguração dos serviços
e seus recursos computacionais associados.

O controle de migração de serviço do EE pode ser usado para 
agrupar mais de um serviço em um único
recurso computacional ou para migrar o serviço para um recurso diferente
para aumentar seu desempenho.

Replicação de serviço é um tipo particular e importante de atualização de composição.
Associado a um balanceamento de carga, é uma estratégia comum para
a construção de sistemas escaláveis~\cite{Amazon2012Practices}.
O EE possibilita a replicação de serviço através da implantação de
múltiplas instâncias do serviço e informando aos seus serviços consumidores
sobre a existência dessas réplicas durante a fase de ligação de serviços.
A quantidade inicial de réplicas é definida por atributo na especificação
do serviço fornecida ao EE, e, depois, pode ser redefinida dinamicamente.
Um trabalho futuro é configurar automaticamente um balancemanto de carga
entre réplicas de um serviço, de forma que o consumidor de um serviço
não tenha a necessidade de saber sobre suas diversas réplicas.

Por fim, o EE fornece opcionalmente a implantação de uma infraestrutura de monitoramento na infraestrutura alvo.
Utilizamos o Ganglia, que coleta métricas do sistema operacional, como consumo de CPU, por exemplo.
As métricas coletadas são enviadas a um serviço previamente configurado no EE.
Esse serviço de monitoramento pode então disparar ações de adaptação com base
nos dados recebidos. Uma ação de adaptação envolve a geração de uma nova especificação
de composição e a atualização da composição em execução de acordo com a nova especificação.

Essas funcionalidades fazem do EE uma opção adequada para uma ferramenta de apoio 
à pesquisa de auto-adaptação de composição de serviços.
O EE facilita a implementação de sistemas adaptativos
por possibilitar que pesquisadores se foquem mais nos problemas de adaptação em
alto nível, abstraindo detalhes altamente específicos do gerenciamento de implantação.
Diferentes pesquisadores desse campo de pesquisa podem se beneficiar ao utilizarem uma plataforma comum,
potencializando a troca de experiência entre eles sobre o processo de implantação. 
Essa troca de experiência é bem mais limitada se os membros da comunidade adotam cada um 
sua própria solução \emph{ad-hoc}.

\end{description}

