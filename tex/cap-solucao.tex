\chapter{Solução proposta}
\label{cap:solucao}

O CHOReOS \ee (EE) é um middleware implementado no contexto deste trabalho.
Uma vez instanciado, ele fornece serviços que automatizam
a implantação de composições de serviços\footnote{Como explicado na Seção~\ref{sec:composicoes}, usaremos os termos 
``composição de serviço'' e ``coreografia'' indistintamente.} 
em ambientes de computação em nuvem,
funcionando no modelo de computação em nuvem denominado Plataforma como um Serviço (PaaS).
O EE possui funcionalidades e características que foram projetadas para auxiliar o
implantador na implantação de composições de grande escala.

Para utilizar o EE, o implantador, usuário do EE, deve descrever a composição a ser implantada
na Linguagem de Descrição Arquitetural do EE, uma especificação de alto nível que
diz \emph{o que} deve ser implantado, e não o \emph{como}. 
Finalmente, o usuário deve fornecer essa descrição ao EE através de sua API remota.

As funcionalidades fornecidas pelo \ee ao usuário são as seguintes:

\begin{itemize}
\item API para automatizar a implantação de composições de serviços em ambientes de computação em nuvem.
\item Criação automatiza de infraestrutura virtualizada (nós na nuvem).
\item Implantação escalável de coreografias de grande escala.
\item Suporte a implantação multi-nuvem.
\item Utilização de serviços de terceiros na composição a ser implantada.
\item Implantação automatizada de infraestrutura de monitoramento dos recursos utilizados.
\item Deleção automática de recursos da nuvem não utilizados.
\item API para escalamento vertical e horizontal.
\end{itemize}

Para a implementação do arcabouço Enactment Engine contribuíram Daniel Cuckier, Carlos Eduardo do Santos, Felipe Pontes, Alfonso Diaz, Nelson Lago, Paulo Moura, Thiago Furtado e demais colegas dos projetos Baile e CHOReOS. O \ee é software livre 
sob a Licença Pública Mozilla 2\footnote{\url{http://www.mozilla.org/MPL/2.0/}} 
e está disponível em \url{http://ccsl.ime.usp.br/enactmentengine}. 

Neste capítulo, nós apresentamos a arquitetura e aspectos de implementação do \ee.   
Destacamos ao final do capítulo
como as decisões arquiteturais e de implementação auxiliam o implantador
a superar os desafios presentes na implantação de composições de grande escala.
Alguns aspectos aqui discutidos serão o tratados em alto nível,
priorizando o que é importante para o entendimento das contribuições
acadêmicas deste trabalho.
Detalhes de mais baixo nível sobre nosso middleware, principalmente do ponto de vista do
usuário, podem ser encontrados no \userguide (Apêndice~\ref{ape:user_guide}).

\section{Execução do \ee}

O \ee é um sistema de middleware de código aberto que primeiramente deve ser instalado e configurado por um \emph{administrador}.
Uma vez em execução, a instância do EE fornece serviços que podem ser consumidos por algum sistema cliente, desenvolvido
e operado pela figura do \emph{implantador}. O administrador e o implantador podem pertencer à mesma organização,
mas é possível que o administrador forneça o EE como um serviço (SaaS) a terceiros, cobrando por sua utilização.
Para esses terceiros a vantagem seria evitar o trabalho de instalação e configuração do EE.
O ambiente de execução do EE é exibido na Figura~\ref{fig:arquitetura} e os componentes envolvidos são descritos a seguir.

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\linewidth]{arquitetura.pdf}
\caption{Ambiente de execução do \choreos \ee.}
\label{fig:arquitetura}
\end{figure}

\begin{itemize}

\item O \emph{provedor de infraestrutura} é um serviço capaz de criar e destruir máquinas virtuais 
(também chamadas de \emph{nós}), normalmente em um ambiente de computação em nuvem. 
Atualmente o \ee suporta o Amazon EC2 e o OpenStack.

\item O \emph{agente de configuração} é executado nos nós alvos
e dispara os scripts que implementam as fases de preparação
e inicialização da implantação dos serviços\footnote{Sobre a nomenclatura das fases de implantação, ver a Seção~\ref{sec:implantacao}.}.
O \ee utiliza o Chef Solo\footnote{\url{http://docs.opscode.com/chef_solo.html}}
como seu agente de configuração.

\item O \emph{cliente do \ee} é um programa ou script desenvolvido
pelo implantador, no qual a especificação da composição de serviços é definida.
Esse script deve enviar a especificação da composição para o \ee
através das operações REST fornecidas pelo \ee.
Uma opção para implementar essas chamadas é utilizar
a biblioteca Java por nós fornecida, que abstrai os detalhes
das chamadas REST.

\item O \emph{\ee} implanta os serviços de uma composição
com base na especificação enviada pelo cliente.
O processo implementado pelo \ee para efetuar a implementação
é descrito na Figura~\ref{fig:processo}, e explicado logo em seguida. 


\end{itemize} 

A Figura~\ref{fig:processo} exibe o processo de implantação de composições
de serviços implementado pelo \ee:

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{processo.pdf}
\caption{Processo de implantação implementado pelo \ee.}
\label{fig:processo}
\end{figure}

\begin{enumerate}

\item \emph{Requisição do cliente:} o EE recebe a especificação da composição a ser implantada.
O formato dessa especificação é descrito na Seção~\ref{sec:spec}.

\item \emph{Seleção/criação de nós}: para cada serviço especificado, o EE seleciona um ou mais nós 
onde o serviço será implantado (um serviço pode ter várias réplicas implantadas). 
Se preciso, o EE requisitará ao provedor de infraestrutura a criação de novos nós.
Esse processo de seleção/criação de nós pode levar em conta os requisitos não-funcionais
dos serviços a serem implantados.
A política de seleção de nós é definida pelo administrador do EE, sendo que novas políticas podem ser criadas.

\item \emph{Geração de scripts}: para cada serviço da composição, 
o EE gera dinamicamente os scripts de preparação do ambiente e inicialização do serviço. 
O EE acessa então o nó alvo selecionado para o serviço,
e configura o agente de configuração desse nó para executar o script gerado.

\item \emph{Atualização dos nós}: para cada nó alvo que receberá serviços da composição,
o EE dispara a execução do agente de configuração, que por sua vez executa os scripts 
de preparação e inicialização dos serviços atribuídos ao nó.
Dessa forma, os serviços entram em estado de execução na infraestrutura alvo.

\item \emph{Ligação entre serviços}: após os serviços terem sido iniciados, 
para cada relação de dependência na coreografia (ex: serviço \textsf{TravelAgency}
depende do serviço \textsf{Airline}), o EE fornece o endereço da dependência 
(ex: \url{http://airline.com/ws}) ao serviço dependente.
Mais informações sobre o processo de ligação são fornecidas na Seção~\ref{sec:ligacao}.

\item \emph{Resposta para o cliente}: o EE responde ao seu cliente,
informando em que nó cada serviço foi implantado
e as URIs de acesso a cada serviço da composição.
O formato da resposta é descrito na Seção~\ref{sec:spec}.

\end{enumerate}

Há também alguns outros passos opcionais que não descrevemos por estarem fora
do escopo deste trabalho. Um exemplo é a implantação da infra-estrutura de monitoramento
dos nós alvos. O agente de monitoramento 
(Ganglia\footnote{\url{http://ganglia.sourceforge.net}})
é implantado nos nós alvos pelo EE e
coleta valores de uso de CPU, memória e disco dos nós.
\todo{para onde isso é enviado?}

\section{Especificação da coreografia}
\label{sec:spec}

O Enactment Engine recebe de seus clientes a especificação da coreografia na forma 
de uma descrição arquitetural com as informações necessárias e suficientes para 
que se possa realizar a implantação da coreografia. 
O Enactment Engine também devolve ao seu cliente informações sobre a implantação da coreografia, 
em especial as localizações de acesso aos serviços. As descrições da coreografia e de sua 
especificação são feitas com uma Linguagens de Descrição Arquitetural, assim como a dos trabalhos vistos no Capítulo~\ref{cap:relacionados}. 
A nossa ADL consiste na descrição de objetos relacionados entre si seguindo 
a estrutura de classes apresentada na Figura~\ref{fig:adl}. 
Em nossa implementação, essa descrição é realizada com representações em XML, 
que são trocadas entre o Enactment Engine e seu cliente. 
A descrição detalhada de cada atributo e o \emph{schema} XML da linguagem
são apresentados no \userguide.

\begin{figure}[!h]
  \centering
  \includegraphics[width=.90\textwidth]{adl.pdf} 
  \caption{Estrutura da descrição arquitetural de uma coreografia}
  \label{fig:adl} 
\end{figure}

\todo{destacar q a chor spec mostra oq, e não o como}

A especificação da coreografia fornece todas as informações para a implantação da composição.
Para cada serviço, especifica-se de onde o pacote do serviço pode ser baixado
e qual o tipo do pacote (WAR, JAR, etc.).
Pode-se também especificar também para a coreografia a existência de serviços
de terceiros que já estão disponíveis na Internet e que devem
ser consumidos por serviços da coreografia.
O implantador pode escrever a especificação da coreografia diretamente em XML
ou utilizar objetos Java (POJOs).
A Listagem~\ref{lst:service_spec} apresenta um trecho da especificação de uma coreografia,
no qual um dos serviços participantes é definido,
incluindo sua dependência de outro serviço da coreografia.

\lstset{
language=Java,
}

{\scriptsize
\begin{lstlisting}[breaklines, caption={Trecho da especificação de uma coreografia.}, label={lst:service_spec}]
airportBusCompanySpec =
  new DeployableServiceSpec(AIRPORT_BUS_COMPANY, ServiceType.SOAP, PackageType.COMMAND_LINE, resourceImpact, serviceVersion, AIRPORT_BUS_COMPANY_JAR_URL, AIRPORT_BUS_COMPANY_PORT, AIRPORT_BUS_COMPANY, numberOfReplicas);
airportBusCompanySpec.setRoles(
  Collections.singletonList(AIRPORT_BUS_COMPANY));
airportBusCompanySpec.addDependency(
  new ServiceDependency(AIRPORT_name, AIRPORT_endpoint));
\end{lstlisting}
}

\section{Ligação entre serviços}
\label{sec:ligacao}

Segundo Dearle~\cite{Dearle2007PastPresentFuture}, componentes podem ser ligados entre si em vários momentos: compilação, montagem, configuração e execução. Em nosso contexto, a ligação deve ser efetuada necessariamente em tempo de execução, pois é somente nesse momento que teremos os endereços completos dos serviços implantados. Uma das possibilidades apontadas por Dearle para efetivação da ligação em tempo de execução é a utilização do padrão de injeção de dependência, conforme introduzido por Fowler~\cite{Fowler2004Inversion}. A injeção de dependências é utilizada em contêineres como o Springer\footnote{\url{http://www.springer.org}}, no qual o middleware passa ao componente referências de suas dependências. No entanto, Dearle ainda alega que há uma falta de arcabouços para a aplicação da injeção de dependência de forma distribuída.

A solução adotada no \ee\ para possibilitar a ligação entre serviços envolve a utilização do middleware para a passagem de endereços dos serviços implantados aos seus consumidores, o que é feito com base na lista de objetos \textsf{ServiceDependency} pertencentes a um \textsf{ChorServiceSpec}. Essa solução consiste na aplicação do padrão de injeção de dependência de forma distribuída, e é similar ao que foi feito nos trabalhos sobre a linguagem Darwin~\cite{Magee1996Dynamic, Magee1994Regis}. Para que esse processo funcione, é preciso que cada serviço na coreografia que possua dependências implemente uma operação denominada \texttt{setInvocationAddress}, por nós padronizada. Essa operação recebe como argumentos as seguintes informações sobre a dependência: papel do serviço, nome do serviço no contexto da coreografia e as URIs de acesso ao serviço.  Em uma coreografia em que, por exemplo, um serviço de agência de viagem dependa do serviço de uma companhia aérea, o \ee\ poderá executar a seguinte invocação ao serviço da agência de viagens : \texttt{setInvocationAddress('Companhia Aérea', 'Nimbus Airline', [ 'http://192.168.56.107:8080/nimbus/ws/' ])}. Nessa solução, a ``inteligência'' em determinar quais serviços satisfazem as necessidades de outros serviços está na camada que produz a entrada do \ee.

\todo{descrever primeiro genericamente, e depois com o setInvocationAddress,
que é apenas uma possível implementação}.

\todo{explicar para que serve o nome do serviço}/

Apesar dos benefícios de uma solução como essa, Dearle~\cite{Dearle2007PastPresentFuture} também alerta sobre a desvantagem em forçar componentes a aderirem convenções de codificação impostas pelo middleware, o que poderia restringir o serviço a uma determinada linguagem de programação ou a algum middleware específico. Reconhecemos que esse problema existe em nossa solução, mas acreditamos que o desenho adotado ameniza os problemas levantados, pois tudo o que o serviço é obrigado a fazer é implementar a operação \texttt{setInvocationAddress} e conhecer os papeis de suas dependências, o que implica em conhecer a interface sintática de cada papel. Dessa forma, nossa solução não restringe o serviço a nenhuma linguagem e possibilita seu uso por outros middlewares que adotem a mesma convenção para o \texttt{setInvocationAddress}.

\section{Interface do \ee}
\label{sec:interface}

Os clientes do \ee utilizam suas funcionalidades por meio de uma API REST, que é descrita nesta seção. 
Por se tratar de uma API REST, o cliente pode ser implementado em qualquer linguagem 
e ambiente que possua alguma biblioteca HTTP. 
Também disponibilizamos um cliente na forma de uma biblioteca na linguagem Java, 
tornando o uso do \ee ainda mais simples para os usuários da linguagem Java, 
atualmente uma das mais utilizadas do mercado. 
Seguimos agora com uma descrição de alto nível de cada uma das operações disponíveis 
na API REST do \ee. Detalhes da API, como os códigos de status HTTP retornados, 
são fornecidos no \userguide.

\begin{description}

\item [Criar coreografia:] registra a especificação de uma coreografia no \ee. 
Essa especificação é a descrição arquitetural da coreografia, 
estruturada de acordo com a classe \textsf{ChorSpec} (ver Seção~\ref{sec:spec}). 
Essa operação não realiza a implantação da coreografia.

\item [Obter coreografia:] obtém informações sobre uma coreografia registrada no \ee. 
Essas informações referem-se à especificação da coreografia e ao estado da implantação 
de seus serviços, como os nós em que os serviços foram implantados, 
no caso de a implantação já ter sido realizada.

\item [Encenar coreografia:] realiza a implantação de uma coreografia já registrada no \ee. 
Ao fim do processo, detalhes do resultado da implantação são retornados na representação XML da coreografia. 
A implementação dessa operação deve possuir duas importantes propriedades: 
1) a falha na encenação de parte da coreografia não deve interromper a encenação do resto da coreografia; 
2) a operação deve ser \emph{idempotente}, ou seja, uma nova requisição para a encenação da mesma 
coreografia não deve tentar implantar os serviços já implantados, 
mas somente aqueles cujas implantações falharam na última execução. 
Para que serviços sejam atualizados, é preciso utilizar um novo valor no atributo ``versão'' da especificação do serviço.

\item [Atualizar coreografia:] registra uma nova versão de uma coreografia no \ee. 
Os serviços atualizados na nova versão da coreografia devem possuir 
um novo número de versão em suas especificações. 
Essa operação, assim como a criação da coreografia, não encena a nova coreografia. 
Para isso, é preciso invocar novamente a operação de encenação.

A atualização de serviços não é o foco de nosso trabalho.
Dessa forma, em nosso trabalho a atualização dos serviços será feita da forma mais simples possível: 
apenas substituindo o serviço existente por sua nova versão. 
Contudo, tal procedimento pode provocar falhas na comunicação entre os serviços de uma coreografia. 
Vários trabalhos \cite{Kramer1990Philosophers, Vandewoude2007Tranquility, Xiaoxing2011VersionConsistent} 
estudam o processo de atualização dinâmica, pelo qual as conversações correntes 
são preservadas durante a atualização de um serviço. 
Embora não esteja no escopo de nosso trabalho, esperamos que a arquitetura do \ee possa ser 
evoluída para que a operação de atualização de coreografia utilize procedimentos seguros de 
atualização dinâmica, dentre os quais destacamos a proposta de Xiaoxing et al~\cite{Xiaoxing2011VersionConsistent}.

\end{description}

Na Listagem~\ref{lst:java_chor_enactment} fornecemos um exemplo de como seria
um programa Java invocando o \ee para implantar uma coreografia.
Nesse exemplo, a classe \textsf{MyChorSpec} está escondendo a declaração
da especificação da coreografia.

\begin{lstlisting}[breaklines, caption={Programa Java que invoca o \ee para implantar uma coreografia.}, label={lst:java_chor_enactment}]
public class Enactment {

    public static void main(String[] args) throws EnactmentException, ChoreographyNotFoundException {

        final String EE_URI = "http://localhost:9102/enactmentengine";
        EnactmentEngine ee = new EnactmentEngineClient(EE_URI);
        ChoreographySpec chorSpec = MyChorSpec.getChorSpec();

        String chorId = ee.createChoreography(chorSpec);
        Choreography chor = ee.enactChoreography(chorId);

        System.out.println(chor); // vamos ver o que aconteceu...
    }
}
\end{lstlisting}


\section{Pontos de extensão}
\label{sec:extensao}

Para lidar com as particularidades do ambiente de cada organização, o Enactment Engine fornece alguns pontos de extensão. Esses pontos de extensão são classes que desenvolvedores devem escrever na linguagem Java e que, de acordo com as configurações do sistema, poderão ser executadas pelo arcabouço.
Neste capítulo descreveremos os pontos de extensão de nosso middleware, 
mostrando as interface associadas a cada um deles.
Para mais detalhes sobre todos os passos necessários para implementar
uma extensão, verificar o \userguide.

\begin{description}

\item [Infraestrutura de nuvem:] implementando a interface \textsf{CloudProvider} é possível o suporte a novas plataforma de computação em nuvem. Atualmente nossa implementação suporta o serviço EC2 do AWS e o OpenStack.

\begin{lstlisting}[frame=trbl, label=lst:cloud_provider, caption=Interface CloudProvider.]
/**
 * Provides access to cloud service functions to create nodes on the cloud.
 * 
 * Each specific provider (e.g. AmazonWS) must have an implementing class 
 * of this interface.
 * 
 */
public interface CloudProvider {

    public String getCloudProviderName();

    public CloudNode createNode(NodeSpec nodeSpec) throws NodeNotCreatedException;

    public CloudNode getNode(String nodeId) throws NodeNotFoundException;

    public List<CloudNode> getNodes();

    public void destroyNode(String id) throws NodeNotDestroyed, NodeNotFoundException;

    public CloudNode createOrUseExistingNode(NodeSpec nodeSpec) throws NodeNotCreatedException;

    public void setCloudConfiguration(CloudConfiguration cloudConfiguration);

}
\end{lstlisting}

\todo{explicar cloud configuration?}

Para facilitar o desenvolvimento de novas implementações,
nós fornecemos uma implementação base, a classe \textsf{JCloudsCloudProvider}.
Ela utiliza a biblioteca JClouds\footnote{\url{http://jclouds.incubator.apache.org/}},
que já é apta a acessar uma ampla gama de provedores de infraestrutura disponíveis no mercado.
Essa implementação base foi utilizada para a implementação das classes 
\textsf{AmazonCloudProvider} e \textsf{OpenStackKeyStoneCloudProvider},
que contaram, respectivamente, com 79 e 96 linhas de código-fonte.

\todo{Classe base: JCloudsCloudProvider}

\item [Política de seleção de nós:] a implementação da interface \textsf{NodeSelector} define uma nova política de alocação de serviços em nós da nuvem, que pode levar em conta os requisitos não-funcionais do serviço e propriedades dos nós à disposição.
Algumas políticas já fornecidas são ``sempre cria um novo nó'' e 
``cria novos nós até um certo limite, depois faz rodízio entre eles''.

\begin{lstlisting}[frame=trbl, label=lst:node_selector, caption=Interface NodeSelector acompanhada de sua classe pai Selector.]
/**
 * Selects a node to apply a given configuration
 * 
 * The selection can consider functional requirements, which is provided by
 * spec.resourceImpact. Implementing classes must use the NodePoolManager 
 * to retrieve nodes AND/OR create new nodes. 
 * NodeSelectors are always accessed as singletons. 
 * Implementing classes must consider concurrent access to the
 * selectNodes method.
 *  
 */
public interface NodeSelector extends Selector<CloudNode, DeployableServiceSpec> {

}

/**
 * Selects objects from a given source according to the requirements. 
 * If necessary, creates new objects using a given factory.
 * 
 * 
 * @param <T>
 *            the class of the selected resource
 * @param <R>
 *            the class of the requirements
 */
public interface Selector<T, R> {

    public List<T> select(R requirements, int objectsQuantity) throws NotSelectedException;

}
\end{lstlisting}

Formas similares dessa funcionalidade são também utilizadas em estudos já apresentados na seção de trabalhos relacionados.  O trabalho de Magee e Kramer~\cite{Magee1997Corba} apresenta a seleção de nós em função da utilização de CPUs nos nós existentes, não havendo possibilidade de utilização de outros critérios, como memória, disco, custo etc. Nos sistemas apresentados por Dolstra et al.~\cite{Dolstra2005Configuration} e Balter et al.~\cite{Balter1998Olan} é preciso que a distribuição dos serviços seja especificada com o uso dos IPs das máquinas nas quais os serviços devem ser implantados, o que não é possível em um ambiente de nuvem. Por fim, o \emph{broker} apresentado por Watson et al. é o componente que mais se assemelha ao nosso NodeSelector, pois os autores deixam claro que várias implementações diferentes são possíveis, considerando-se diferentes tipo de requisitos e diferentes fontes de monitoramento. Como a escolha é feita em tempo de execução do serviço, seria também possível uma seleção que independa de IPs estabelecidos em tempo de projeto. No entanto, os autores não explicam como os usuários de seu sistema, os provedores de infraestrutura, deveriam proceder para criar seus próprios \emph{brokers} personalizados.

Para avançar em relação às limitações dos trabalhos anteriormente citados,  consideramos como requisitos principais a dinamicidade do ambiente de nuvem, que nos impede de conhecer os IPs das máquinas em tempo de configuração, bem como a flexibilidade para que cada organização determine os requisitos de distribuição dos serviços.

\item [Tipos de pacotes de serviços:] um serviço pode ser distribuído por diferentes tipos de pacotes, como em um JAR ou em um WAR, por exemplo. Como existem muitas outras opções, é preciso que esse seja um ponto de flexibilidade. Para cada novo tipo de pacote, pode-se escrever um template de um \emph{cookbook} Chef que implemente a preparação e a inicialização do serviço. \todo{falar mais dos tokens no template...}

\item \emph{Package type:} the current supported types
are JAR and WAR packages. Users may add support to a new package type
by writing a Chef cookbook template.
One example would be a Python web service deployment in an Nginx server.

\item [Tipos de serviços:] a ligação entre serviços de uma coreografia depende da passagem de endereços que é feita do \ee para os serviços. Para isso, o EE precisa invocar a operação \texttt{setInvocationAddres} dos serviços. A implementação de tal invocação dar-se-á de forma diferente se o serviço for SOAP ou REST. A implementação da interface \textsf{ContextSender} possibilita ao EE realizar a invocação da operação \texttt{setInovcationAddress} em serviços de outras tecnologias (JMS e CORBA por exemplo). Nota-se que para cada um desses tipos de serviços adicionados pelo usuário, é preciso criar uma convenção para a assinatura sintática da operação \texttt{setInvocationAddres}.

\begin{lstlisting}[frame=trbl, label=lst:context_sender, caption=Interface ContextSender.]
public interface ContextSender {

    /**
     * Calls setInvokationAddress operation on service 
     * in the serviceEndpoint.
     * So, the service in endpoint will know that its 
     * partner named partnerName with partnerRole is 
     * realized by instances in partnerEndpoints.
     * 
     * @param serviceEndpoint
     * @param partnerRole
     * @param partnerName
     * @param partnerEndpoints
     * @throws ContextNotSentException
     *             if context was not successfully set
     */
    public void sendContext(String serviceEndpoint, 
                            String partnerRole, 
                            String partnerName, 
                            List<String> partnerEndpoints) throws ContextNotSentException;
}
\end{lstlisting}

\end{description}


\section{Aspectos gerais de implementação}

\todo{falar de como lidamos com a questão das imagens}.

\section{Discussão: auxiliando implantações em grande escala}

Nesta seção discutiremos como as características arquiteturais e de implementação do \ee
impactam na implantação de composições de serviço de grande escala.
Explicaremos como o EE contribui para a resolução de cada um dos desafios
apresentados na Seção~\ref{sec:desafios}.
Durante a discussão destacaremos como uma solução de middleware traz vantagens
sobre abordagens \emph{ad-hoc} de implantação em nosso contexto.
Essa discussão, suportada pelo efetivo funcionamento do EE demonstrado por sua avaliação
(Capítulo~\ref{cap:avaliacao}), fornece também subsídios para a implementação de novos sistemas
de implantação de grande escala, mesmo que não voltados a composições de serviços,
e até mesmo para soluções \emph{ad-hoc}.

\begin{description}

\item [Processo:]

Tornar a implantação de sistemas ``\emph{Internet-scale}'' processos totalmente automatizados
é necessário para que a implantação se torne testável, flexível e confiável~\cite{Hamilton2007InternetScale},
conforme discutido na Seção~\ref{sec:implantacao}.
O EE possibilita a automação do processo de implantação
graças a sua interface remota (REST), que recebe a especificação
da composição a ser implantada e devolve o resultado do processo.
Embora uma interface gráfica para a implantação de composições seja viável,
tal opção não favorece a implantação automatizada,
e por isso não foi priorizada em nosso trabalho.

O uso de uma especificação declarativa,
como já utilizado em outros trabalhos~\cite{Balter1998Olan,Magee1996Dynamic},
também facilita o desenvolvimento do script de implantação
para cada nova composição a ser implantada.
Isso ocorre porque com uso de uma linguagem declarativa o implantador descreve em alto nível apenas
\emph{o que} deve ser implantado, e não os detalhes de \emph{como} deve ser implantado.
O uso de linguagens declarativas requer algum tipo de middleware que interprete
a descrição declarativa, executando as ações adequadas.
Portanto, soluções \emph{ad-hoc} dificilmente usariam linguagens declarativas,
sendo em geral orientadas ao uso de scripts.

O EE segue a tendência atual na implantação de sistemas de grande escala, que é o uso
de recursos elásticos possibilitados pela computação em nuvem.
Recursos virtualizados fornecidos pela nuvem potencializam
a automação do processo de implantação~\cite{Humble2011Continuous}.
Diferentemente dos cenários estudados em trabalhos anteriores sobre
implantação de sistemas baseados em componentes~\cite{Balter1998Olan,Magee1996Dynamic},
em uma infraestrutura de nuvem os nós alvos são mais dinâmicos. Não é possível conhecer os endereços IPs
dos nós alvos quando se está escrevendo a especificação da composição a ser implantada.
A ligação entre serviços deve ser feita em tempo de execução, o que o EE faz via \texttt{setInvocationAddress},
e a política de alocação de nós deve ser flexível, i.e.,
um serviço não deve ser alocado a um IP estático antes do tempo de implantação.
O EE possibilita que políticas de alocação de nós
escolham em tempo de implantação em que nós um serviço deve ser implantado,
considerando inclusive o casamento de requisitos não-funcionais do serviço
com características dos nós disponíveis.

\item [Falhas de terceiros:]

Seguindo recomendações gerais feitas por Nygard~\cite{Nygard2009Release},
adotamos no \ee uma abordagem simples para tratar falhas externas.
A lógica de invocação a sistemas externos foi encapsulada em uma classe, 
chamada \textsf{Invoker}, que foi usada de forma disciplinada pelo projeto.
Toda vez que se deve acessar um sistema externo, utiliza-se um \emph{invoker}.
Nosso \textsf{Invoker} recebe os seguintes parâmetros:
uma \emph{tarefa}, que é uma rotina que se comunicará com algum sistema externo,
a quantidade de \emph{tentativas} para executar a tarefa,
o \emph{timeout} de cada tentativa, e um \emph{intervalo} entre as tentativas.

Uma instância do \textsf{Invoker} deve ser configurada 
de acordo com sua tarefa (por exemplo, nós descobrimos que três tentativas
não é o suficiente para transferência de arquivos por SCP).
Em vez de ter esses valores fixados no código-fonte, eles são explicitamente
ajustados em arquivos de configuração.
Desta forma, pode-se facilmente ajustar esses valores de acordo com 
as características do ambiente alvo.
Portanto, essa abordagem é também uma estratégia para colaborar 
com a heterogeneidade de plataformas e tecnologias.
A classe \textsf{Invoker} pode ser decorada\footnote{Ver padrão de projeto \emph{decorator}~\cite{GoF1995Patterns}.} 
para adaptar dinamicamente valores de timeouts 
baseando-se em heurísticas definidas programaticamente 
que utilizem o histórico de execução dos \emph{invokers}.

O EE garante a utilização correta e disciplinada dos \emph{invokers} nos momentos adequados e necessários.
Isso fornece uma robustez mais facilmente proporcionada por sistemas de middleware,
nos quais interesses transversais podem ser implementados sem que o desenvolvedor da aplicação 
(o script de implantação em nosso caso) tenha que se preocupar com isso.

O EE adota uma estratégia particular par lidar com falhas durante a criação de novas VMs.
Quando uma requisição chega, o EE tenta criar um novo nó.
Se a criação falha ou demora muito, um nó já criado é recuperado de uma reserva de nós ociosos.
Essa estratégia evita que se tenha que esperar novamente pelo tempo de se criar um novo nó.
A capacidade inicial da reserva é definida por configuração
e ela é preenchida cada vez que a criação de um nó é requisitada.
Se o tamanho da reserva é reduzido e alcança um dado limite,
a capacidade é aumentada, de forma a tentar evitar uma situação futura
de se encontrar uma reserva vazia em um momento de necessidade.

A abordagem da reserva impõe um custo extra de se manter algumas VMs a mais
em execução (em um estado ocioso). Contudo, esse problema é tratado
pelo EE por um algoritmo de gerenciamento distribuído em cada nó:
se o nó está em um estado ocioso por $N-1$ minutos, onde $N$ é um limite
de tempo que implica custo adicional, o nó envia ao EE um pedido para 
sua própria destruição. Assim, depois de um tempo de inatividade no EE,
a reserva se torna vazia em algum momento, sendo preenchida novamente
somente quando chegam novas requisições de criação de nós.
%This distributed approach alleviates the need to have the \ee periodically check
%the status of the machines to decide whether they should be removed.

Considerando que o tempo de criação de um nó é bem maior que o tempo de inicialização (\emph{boot})
desse nó, uma melhoria a ser feita na reserva de nós ociosos é manter o nó ocioso desligado
até o momento de uso, uma vez que provedores de infraestrutura, como a Amazon,
costumam não cobrar por máquinas desligadas.
Essa abordagem pode diminuir um pouco o desempenho da reserva de nós,
mas irá economizar mais recursos.

Outra prática importante relacionada a tolerância a falhas é a 
\emph{degradação suave}~\cite{Brewer2001GiantScale,Hamilton2007InternetScale}.
Em nosso contexto, degradação suave significa que se um serviço não foi 
implantado apropriadamente, não é aceitável que o processo de implantação
de toda a composição seja interrompido.
Com o EE, se algum serviço não é implantado, o processo de implantação continua,
e a resposta do EE fornece informações sobre os problemas ocorridos,
possibilitando ações de recuperação.

Contudo, é importante destacar que a responsabilidade pela degradação suave
debe ser compartilhada com a implementação dos serviços, uma vez que cada serviço
debe saber como se comportar na ausência de uma ou mais de suas dependências.
De outra forma, cada serviço se tornaria um \emph{ponto de falha único} na composição,
o que é altamente indesejável.

\item [Disponibilidade:]

A especificação de um serviço na ADL do \ee possibilita a definição da quantidade de réplicas
de um serviço a ser implantado pelo EE.
Essa quantidade inicial de réplicas pode ser alterada pelo implantador em tempo de execução
com a atualização da especificação da coreografia.
A definição da quantidade adequada de réplicas, definida pelo implantador, permite não só uma melhora
de desempenho, mas também um aumento na disponibilidade do serviço, já que uma falha em uma réplica
específica não afeta as outras réplicas disponíveis.

Por questões de simplificação, em nosso trabalho omitimos a relação que serviços possuem com bancos de dados.
Dessa forma, é importante que versões futuras do EE contemplem a automação da implantação de bancos de dados
a serem utilizados pelos serviços implantados. Nesse estágio, deverá ser considerado também a replicação
do banco de dados, e que os dados são utilizados simultaneamente por várias réplicas do serviço.

\item [Escalabilidade:]

Embora o conhecimento de programação concorrente para implementar
um processo de implantação escalável seja básico (dentro do contexto de computação concorrente),
programação concorrente por si própria é difícil e propensa a erros.
Muitas vezes, linguagens de scripts não oferecem um bom suporte à programação concorrente.
O tratamento adequado de falhas de terceiros também é um requisito importante
para a obtenção de um sistema escalável.
Portanto, implementar concorrência e tratamento a falhas na camada de middlware
é um passo significativo em facilitar a implementação efetiva de um
processo de implantação escalável.
No Capítulo~\ref{cap:avaliacao} avaliaremos em detalhes a escalabilidade fornecida pelo \ee.

\item [Heterogeneidade:]

Na Seção~\ref{sec:extensao} apresentamos os pontos de extensão do \ee,
que permitem mais facilmente equipá-lo para diversos provedores de infraestrutura
e tecnologias de desenvolvimento e empacotamento de serviços.
Essa flexibilidade ajuda a superar
as atuais limitações de soluções de Plataformas como um Serviço
que restrigem as opções tecnológicas disponíveis aos desenvolvedores de aplicações.
Essas restrições normalmente se aplicam justamente sobre
provedor de infraestruturas e a linguagem de programação da aplicação.

Suportar variações de um padrão é um desafio para sistemas de middleware.
Adequar um middleware para a particularidade de uma aplicação pode não ser fácil.
No suporte a diferentes tecnologias, as abordagens \emph{ad-hoc} encontram realmente um espaço de importância.
No entanto, uma vez que a adequação para uma nova tecnologia seja feita no middleware,
pode-se aplicar mais facilmente a melhoria para diferentes aplicações utilizando essa
mesma nova tecnologia.

\item [Múltiplas organizações:]

O \ee possui dois principais mecanismos para implantar composições cujos serviços
pertencem a diferentes organizações.
O primeiro mecanismo é a definição da ``conta de nuvem'' a ser usada na implantação de um serviço.
Essa definição é feita na especificação do serviço e deve bater com configurações
previamente feitas pelo administrador no EE.
Uma ``conta de nuvem'' não indica apenas a nuvem alvo (Amazon, por exemplo),
mas também que vai pagar pela infraestrutura (qual conta da Amazon será utilizada, por exemplo).
Uma vez que os serviços de cada organização sejam configurados para serem implantados
nas contas de nuvem adequadas, o EE irá implantar adequadamente uma composição
multi-organizacional.
No entanto essa abordagem ainda apresenta limitações sérias no quesito de segurança,
pois a configuração da conta de nuvem deve ser fornecida ao administrador do EE,
que seria uma das organizações ou um terceiro.
Esse e outros problemas surgem do fato que diferentes organizações teriam que
compartilhar uma mesma instância do EE.

O segundo mecanismo é a utilização da entidade \emph{serviço legado} na especificação da composição.
O serviço legado é um serviço já existente e disponível na Internet, e que portanto
não será implantado pelo EE.
A utilidade em utilizar esse mecanismo está na fase de ligação
entre serviços, pois o EE irá fornecer
aos serviços implantados os endereços dos serviços legados declarados como suas dependências.
A maior limitação dessa abordagem é a dificuldade em se lidar com a alteração de URIs
dos serviços legados.
Quando isso ocorre, uma nova especificação da composição deve ser feita e enviada ao EE,
mas o problema é saber \emph{quando} isso deve ser feito.

Considerando as limitações dos mecanismos até aqui implementados,
divisamos como importante trabalho futuro uma arquitetura de federação entre instâncias do EE.
Caso um serviço $S_A$, implantado com o EE pela organização $O_A$, dependa de um serviço legado $B$,
também implantado com o EE, mas para a organização $O_B$, a instância do EE em $O_B$ poderia
manter a instância do EE em $O_A$ informada sobre o estado de $S_B$.
Para que essa funcionalidade seja implementada é preciso projetar um protocolo
de comunicação entre instâncias do EE.

Nesse estágio proposto (federação dos sistemas implantadores de cada organização) uma abordagem
orientada a middleware se torna importante por questão de padronização.
Abordagens \emph{ad-hoc} deveriam ser desenvolvidas de forma coordenada entre as diferentes organizações,
o que seria mais custoso do que a adoção de uma plataforma comum.

\item [Adaptabilidade:]

O \ee por si só não garante que uma composição será autonômica ou auto-adaptativa.
Contudo, ele fornece suporte para o desenvolvimento de tais sistemas.

Sistemas auto-adaptativos e autonômicos precisam estar cientes
e ter pleno controle das atividades de implantação.
Para empoderar tais sistemas, o EE fornece informação e controle
das seguintes funcionalidades:

\begin{itemize}
\item atualização das composições;
\item migração de serviços;
\item replicação de serviços;
\item implantação de infraestrutura de monitoramento.
\end{itemize}

Atualização de composições de serviços podem ser necessárias quando
as regras de negócio ou os requisitos não-funcionais mudam.
O EE permite, por uma API REST, a adição, remoção e reconfiguração dos serviços
e seus recursos computacionais associados.

O controle de migração de serviço do EE pode ser usado para 
agrupar mais de um serviço em um único
recurso computacional ou para migrar o serviço para um recurso diferente
para aumentar seu desempenho.

Replicação de serviço é um tipo particular e importante de atualização de composição.
Associado a um balanceamento de carga, é uma estratégia comum para
a construção de sistemas escaláveis~\cite{Amazon2012Practices}.
O EE possibilita a replicação de serviço através da implantação de
múltiplas instâncias do serviço e informando aos seus serviços consumidores
sobre a existência dessas réplicas durante a fase de ligação de serviços.
A quantidade inicial de réplicas é definida por atributo na especificação
do serviço fornecida ao EE, e, depois, pode ser redefinida dinamicamente.
Um trabalho futuro é configurar automaticamente um balancemanto de carga
entre réplicas de um serviço, de forma que o consumidor de um serviço
não tenha a necessidade de saber sobre suas diversas réplicas.

Por fim, o EE fornece opcionalmente a implantação de uma infraestrutura de monitoramento na infraestrutura alvo.
Utilizamos o Ganglia, que coleta métricas do sistema operacional, como consumo de CPU, por exemplo.
As métricas coletadas são enviadas a um serviço previamente configurado no EE.
Esse serviço de monitoramento pode então disparar ações de adaptação com base
nos dados recebidos. Uma ação de adaptação envolve a geração de uma nova especificação
de composição e a atualização da composição em execução de acordo com a nova especificação.

Essas funcionalidades fazem do EE uma opção adequada para uma ferramenta de apoio 
à pesquisa de auto-adaptação de composição de serviços.
O EE facilita a implementação de sistemas adaptativos
por possibilitar que pesquisadores se foquem mais nos problemas de adaptação em
alto nível, abstraindo detalhes altamente específicos do gerenciamento de implantação.
Diferentes pesquisadores desse campo de pesquisa podem se beneficiar ao utilizarem uma plataforma comum,
potencializando a troca de experiência entre eles sobre o processo de implantação. 
Essa troca de experiência é bem mais limitada se os membros da comunidade adotam cada um 
sua própria solução \emph{ad-hoc}.

\end{description}

